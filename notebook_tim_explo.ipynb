{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33631\\AppData\\Local\\Temp\\ipykernel_138096\\3408994771.py:16: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "import pickle\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score \n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from namematcher import NameMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_path = \"Data/raw_data/node_information.csv\"\n",
    "test_set_path = \"Data/raw_data/testing_set.txt\"\n",
    "train_set_path = \"Data/raw_data/training_set.txt\"\n",
    "random_preds_path = \"Data/raw_data/random_predictions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(graph, train_set_ratio):\n",
    "    \"\"\"\n",
    "    Graph pre-processing step required to perform supervised link prediction\n",
    "    Create training and test sets\n",
    "    \"\"\"    \n",
    "    # --- Step 1: Generate positive edge samples for testing set ---\n",
    "    residual_g = graph.copy()\n",
    "    test_pos_samples = []\n",
    "      \n",
    "    # Store the shuffled list of current edges of the graph\n",
    "    edges = list(residual_g.edges())\n",
    "    np.random.shuffle(edges)\n",
    "    \n",
    "    # Define number of positive test samples desired\n",
    "    test_set_size = int((1.0 - train_set_ratio) * graph.number_of_edges())\n",
    "    train_set_size = graph.number_of_edges() - test_set_size\n",
    "    \n",
    "    # Remove random edges from the graph, leaving it connected\n",
    "    # Fill in the blanks\n",
    "    for i,edge in enumerate(edges[:test_set_size]):\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "        \n",
    "        # Remove the edge\n",
    "        residual_g.remove_edge(edge[0], edge[1])\n",
    "        \n",
    "        # Add the removed edge to the positive sample list \n",
    "        test_pos_samples.append(edge)\n",
    "        \n",
    "        \n",
    "    # --- Step 2: Generate positive edge samples for training set ---\n",
    "    # The remaining edges are simply considered for positive samples of the training set\n",
    "    train_pos_samples = list(residual_g.edges())\n",
    "        \n",
    "        \n",
    "    # --- Step 3: Generate the negative samples for testing and training sets ---\n",
    "    # Fill in the blanks\n",
    "\n",
    "    print(\"compute negative samples\")\n",
    "    train_neg_samples = []\n",
    "    test_neg_samples = []\n",
    "\n",
    "    print('train neg samples')\n",
    "    i = 0\n",
    "    while i < train_set_size:\n",
    "        a = np.random.choice(nx.nodes(G),1)[0]\n",
    "        b = np.random.choice(nx.nodes(G),1)[0]\n",
    "        if (a,b) not in edges and (a,b) not in train_neg_samples:\n",
    "            i+=1\n",
    "            train_neg_samples.append((a,b))\n",
    "\n",
    "    print('test neg samples')\n",
    "    j = 0\n",
    "    while j < test_set_size:\n",
    "        a = np.random.choice(nx.nodes(G),1)[0]\n",
    "        b = np.random.choice(nx.nodes(G),1)[0]\n",
    "        if (a,b) not in edges and (a,b) not in test_neg_samples and (a,b) not in train_neg_samples:\n",
    "            j+=1\n",
    "            test_neg_samples.append((a,b))\n",
    "\n",
    "\n",
    "    print(\"done\")\n",
    "    \n",
    "    # --- Step 4: Combine sample lists and create corresponding labels ---\n",
    "    # For training set\n",
    "    print(\"final step\")\n",
    "    train_samples = train_pos_samples + train_neg_samples\n",
    "    train_labels = [1 for _ in train_pos_samples] + [0 for _ in train_neg_samples]\n",
    "    # For testing set\n",
    "    test_samples = test_pos_samples + test_neg_samples\n",
    "    test_labels = [1 for _ in test_pos_samples] + [0 for _ in test_neg_samples]\n",
    "    \n",
    "    return train_samples, train_labels, test_samples, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>new_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26953</th>\n",
       "      <td>9909192</td>\n",
       "      <td>1999</td>\n",
       "      <td>physical auxiliary field in supersymmetric qcd...</td>\n",
       "      <td>Noriaki Kitazawa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supersymmetry breaking it is shown that the au...</td>\n",
       "      <td>26953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20372</th>\n",
       "      <td>9703176</td>\n",
       "      <td>1997</td>\n",
       "      <td>a note on the picard-fuchs equations for n 2 s...</td>\n",
       "      <td>J. M. Isidro, A. Mukherjee, J. P. Nunes, H. J....</td>\n",
       "      <td>Int.J.Mod.Phys.</td>\n",
       "      <td>a concise presentation of the pf equations for...</td>\n",
       "      <td>20372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19520</th>\n",
       "      <td>9611172</td>\n",
       "      <td>1996</td>\n",
       "      <td>on orbifolds of 0 2 models</td>\n",
       "      <td>Ralph Blumenhagen, Savdeep Sethi</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>we study orbifolds of 0 2 models including som...</td>\n",
       "      <td>19520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  pub_year                                              title  \\\n",
       "26953  9909192      1999  physical auxiliary field in supersymmetric qcd...   \n",
       "20372  9703176      1997  a note on the picard-fuchs equations for n 2 s...   \n",
       "19520  9611172      1996                         on orbifolds of 0 2 models   \n",
       "\n",
       "                                                 authors     journal_name  \\\n",
       "26953                                   Noriaki Kitazawa              NaN   \n",
       "20372  J. M. Isidro, A. Mukherjee, J. P. Nunes, H. J....  Int.J.Mod.Phys.   \n",
       "19520                   Ralph Blumenhagen, Savdeep Sethi       Nucl.Phys.   \n",
       "\n",
       "                                                abstract  new_ID  \n",
       "26953  supersymmetry breaking it is shown that the au...   26953  \n",
       "20372  a concise presentation of the pf equations for...   20372  \n",
       "19520  we study orbifolds of 0 2 models including som...   19520  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_df = pd.read_csv(information_path, header=None)\n",
    "information_df.columns = [\"ID\",'pub_year','title','authors','journal_name','abstract']\n",
    "### !!!! We have to use new index starting from 0 because of the implementation of karate-club library\n",
    "information_df = information_df.assign(new_ID = [i for i in range(information_df.shape[0])])\n",
    "information_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54501</th>\n",
       "      <td>0</td>\n",
       "      <td>18854</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36609</th>\n",
       "      <td>0</td>\n",
       "      <td>26761</td>\n",
       "      <td>4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455266</th>\n",
       "      <td>1</td>\n",
       "      <td>24105</td>\n",
       "      <td>23780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105393</th>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>27189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337693</th>\n",
       "      <td>1</td>\n",
       "      <td>19786</td>\n",
       "      <td>18309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  node1  node2\n",
       "54501       0  18854   1877\n",
       "36609       0  26761   4153\n",
       "455266      1  24105  23780\n",
       "105393      0    912  27189\n",
       "337693      1  19786  18309"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_set = pd.read_csv(train_set_path, sep =\" \", header = None)\n",
    "pre_train_set.columns = ['node1','node2','label']\n",
    "### !!! we will use the new indices!!! (see information_df for correspondances)\n",
    "pre_train_set = (pre_train_set\n",
    "    .merge(information_df[['ID','new_ID']], how = 'left', left_on = ['node1'], right_on = ['ID'])\n",
    "    .drop(columns = ['node1','ID'])\n",
    "    .rename(columns = {'new_ID':'node1'})\n",
    "    .merge(information_df[['ID','new_ID']], how = 'left', left_on = ['node2'], right_on = ['ID'])\n",
    "    .drop(columns = ['node2','ID'])\n",
    "    .rename(columns = {'new_ID':'node2'})\n",
    ")\n",
    "pre_train_set.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>212171</td>\n",
       "      <td>9910069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32472</th>\n",
       "      <td>204112</td>\n",
       "      <td>9902116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25188</th>\n",
       "      <td>9810123</td>\n",
       "      <td>9805097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25451</th>\n",
       "      <td>12265</td>\n",
       "      <td>209125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30444</th>\n",
       "      <td>303218</td>\n",
       "      <td>9601175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         node1    node2\n",
       "9178    212171  9910069\n",
       "32472   204112  9902116\n",
       "25188  9810123  9805097\n",
       "25451    12265   209125\n",
       "30444   303218  9601175"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv(test_set_path, sep =\" \", header = None)\n",
    "test_set.columns = ['node1','node2']\n",
    "test_set.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pre_train_set.drop(columns = ['label'])\n",
    "y = pre_train_set[['label']]\n",
    "train_samples, validation_samples, train_labels, validation_labels = train_test_split(X,y, test_size=0.2, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([train_samples, train_labels], axis = 1).reset_index(drop = True)\n",
    "validation_set = pd.concat([validation_samples, validation_labels], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information pre_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "pub_year           0\n",
       "title              0\n",
       "authors         4033\n",
       "journal_name    7472\n",
       "abstract           0\n",
       "new_ID             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_df = information_df.fillna({'authors':'', 'journal_name':''})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_df.authors = information_df.authors.apply(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"Data/processed_data/information.csv\"):\n",
    "    information_df = pickle.load(open(\"Data/processed_data/information.csv\",'rb'))\n",
    "else:\n",
    "    information_df['title_lemma'] = information_df.title.apply(lambda x: [token.lemma_ for token in spacy_nlp(x) if not token.is_punct if not token.is_digit if not token.is_stop])\n",
    "    pickle.dump(information_df, open(\"Data/processed_data/information.csv\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles based graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set(np.concatenate((train_set.node1,train_set.node2), axis = 0))\n",
    "edges = set(train_set.query(\"label == 1\").apply(lambda x: (x.node1,x.node2), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes: 27770\n",
      "The number of edges: 267828\n"
     ]
    }
   ],
   "source": [
    "G_articles = nx.Graph()\n",
    "G_articles.add_nodes_from(nodes)\n",
    "G_articles.add_edges_from(edges)\n",
    "\n",
    "print(\"The number of nodes: {}\".format(G_articles.number_of_nodes()))\n",
    "print(\"The number of edges: {}\".format(G_articles.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors co-authorship based graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# convert to lower case, remove punctuation, strip the names\n",
    "authors_raw_set = set([auth.strip().lower().translate(str.maketrans('', '', string.punctuation)) for list_auth in information_df.authors for auth in list_auth if len(auth)>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name matching: to make identify people name by different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from namematcher import NameMatcher\n",
    "name_matcher = NameMatcher()\n",
    "\n",
    "def compute_unique_names(authors_raw_set):\n",
    "    \"\"\"\n",
    "    one author can be named differently on different papers\n",
    "    this function aims at finding a 'representant' (longest name that describe an author) for each \n",
    "    author\n",
    "    inputs:\n",
    "        - authors_raw_set: set of previously extracted author names\n",
    "    outputs:\n",
    "        - dict: keys are the name in authors_raw_set and the values are the representant\n",
    "    \"\"\"\n",
    "    representant_dict = {}\n",
    "    attributed_nodes = [] # names that already have a representant\n",
    "    for name in tqdm(authors_raw_set, position = 0):\n",
    "        sim_list = [] # similar names \n",
    "        if name not in attributed_nodes:\n",
    "            for name2 in authors_raw_set:\n",
    "                try:\n",
    "                    if name != name2 and name[0]==name2[0] and name2 not in attributed_nodes:\n",
    "                        # two names need to start by the same letter to be consider as potential equivalents\n",
    "                        score = name_matcher.match_names(name, name2)\n",
    "                        if score > 0.9: # if names are close enough\n",
    "                            sim_list.append(name2)\n",
    "                except:\n",
    "                    continue\n",
    "            sim_list.append(name) # the representant is in this list\n",
    "            attributed_nodes.extend(sim_list) # we have fund a representant for those names\n",
    "            representant = max(sim_list, key=len) # the representant is the longest name\n",
    "            for name in sim_list: # all those names have the same representant\n",
    "                representant_dict[name] = representant\n",
    "    return(representant_dict)\n",
    "\n",
    "if os.path.isfile('Data/processed_data/representant_dict.pkl'):\n",
    "    representant_dict = pickle.load(open('Data/processed_data/representant_dict.pkl','rb'))\n",
    "else:\n",
    "    representant_dict = compute_unique_names(authors_raw_set)\n",
    "    pickle.dump(representant_dict, open('Data/processed_data/representant_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each name to its representant value\n",
    "information_df.authors = information_df.authors.apply(lambda x: [representant_dict[auth.strip().lower().translate(str.maketrans('', '', string.punctuation))] for auth in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique index for each author\n",
    "representants_list = list(set(representant_dict.values()))\n",
    "authors2idx = {k: v for v, k in enumerate(representants_list)}\n",
    "\n",
    "information_df[\"authors_id\"] = information_df.authors.apply(lambda x: [authors2idx[auth] for auth in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>new_ID</th>\n",
       "      <th>title_lemma</th>\n",
       "      <th>authors_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>9202058</td>\n",
       "      <td>1992</td>\n",
       "      <td>hamiltonian reduction and classical extended s...</td>\n",
       "      <td>[katsushi ito, jens ole madsen]</td>\n",
       "      <td>Phys.</td>\n",
       "      <td>we present a systematic construction of classi...</td>\n",
       "      <td>10397</td>\n",
       "      <td>[hamiltonian, reduction, classical, extend, su...</td>\n",
       "      <td>[12299, 14012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26823</th>\n",
       "      <td>9909060</td>\n",
       "      <td>1999</td>\n",
       "      <td>branched polymer revisited</td>\n",
       "      <td>[hajime aoki, satoshi iso, hikaru kawai, yoshi...</td>\n",
       "      <td>Prog.Theor.Phys.</td>\n",
       "      <td>we show that correlation functions for branche...</td>\n",
       "      <td>26823</td>\n",
       "      <td>[branch, polymer, revisit]</td>\n",
       "      <td>[2550, 4810, 12325, 13907]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  pub_year                                              title  \\\n",
       "10397  9202058      1992  hamiltonian reduction and classical extended s...   \n",
       "26823  9909060      1999                         branched polymer revisited   \n",
       "\n",
       "                                                 authors      journal_name  \\\n",
       "10397                    [katsushi ito, jens ole madsen]             Phys.   \n",
       "26823  [hajime aoki, satoshi iso, hikaru kawai, yoshi...  Prog.Theor.Phys.   \n",
       "\n",
       "                                                abstract  new_ID  \\\n",
       "10397  we present a systematic construction of classi...   10397   \n",
       "26823  we show that correlation functions for branche...   26823   \n",
       "\n",
       "                                             title_lemma  \\\n",
       "10397  [hamiltonian, reduction, classical, extend, su...   \n",
       "26823                         [branch, polymer, revisit]   \n",
       "\n",
       "                       authors_id  \n",
       "10397              [12299, 14012]  \n",
       "26823  [2550, 4810, 12325, 13907]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nodes and edges\n",
    "pre_edges = list(information_df.authors_id.apply(lambda x : [(x[i],x[j]) for i in range(len(x)) for j in range(len(x)) if i>j]))\n",
    "authors_edges = [edge for list_edge in pre_edges for edge in list_edge]\n",
    "authors_edges_dict = Counter(authors_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes: 14447\n",
      "The number of edges: 29111\n"
     ]
    }
   ],
   "source": [
    "G_authors = nx.Graph()\n",
    "G_authors.add_nodes_from(authors2idx.values())\n",
    "G_authors.add_weighted_edges_from([(a,b,weight) for (a,b),weight in authors_edges_dict.items()])\n",
    "\n",
    "print(\"The number of nodes: {}\".format(G_authors.number_of_nodes()))\n",
    "print(\"The number of edges: {}\".format(G_authors.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Walklets\n",
    "from karateclub import Walklets\n",
    "if os.path.isfile('Data/processed_data/articles_walklets_embeddings.pkl'):\n",
    "    walklets_articles_embeddings = pickle.load(open('Data/processed_data/articles_walklets_embeddings.pkl','rb'))\n",
    "else:\n",
    "    walklets = Walklets(walk_length=80) # we leave the defaults parameters for the other values\n",
    "    walklets.fit(G_articles)\n",
    "    walklets_articles_embeddings = walklets.get_embedding()\n",
    "    pickle.dump(walklets_articles_embeddings, open('Data/processed_data/articles_walklets_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Node2Vec\n",
    "from karateclub import Node2Vec\n",
    "if os.path.isfile('Data/processed_data/articles_node2vec_embeddings.pkl'):\n",
    "    articles_node2vec_embeddings = pickle.load(open('Data/processed_data/articles_node2vec_embeddings.pkl','rb'))\n",
    "else:\n",
    "    node2vec = Node2Vec(walk_length=15) # we leave the defaults parameters for the other values\n",
    "    node2vec.fit(G_articles)\n",
    "    articles_node2vec_embeddings = node2vec.get_embedding()\n",
    "    pickle.dump(articles_node2vec_embeddings, open('Data/processed_data/articles_node2vec_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute abstracts embeddings using specter network\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "if os.path.isfile('Data/processed_data/abstracts_embeddings.pkl'):\n",
    "    abstracts_embeddings = pickle.load(open('Data/processed_data/abstracts_embeddings.pkl','rb'))\n",
    "else:\n",
    "    \n",
    "    # load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "    model = AutoModel.from_pretrained('allenai/specter')\n",
    "    abstracts_embeddings = []\n",
    "    for i in tqdm(range(information_df.shape[0]), position = 0):\n",
    "        article = information_df.loc[i]\n",
    "        title = article.title\n",
    "        abstract = article.abstract\n",
    "        paper = [{'title':title, 'abstract':abstract}]\n",
    "\n",
    "        # concatenate title and abstract\n",
    "        title_abs = [d['title'] + tokenizer.sep_token + (d.get('abstract') or '') for d in paper]\n",
    "        # preprocess the input\n",
    "        inputs = tokenizer(title_abs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        result = model(**inputs)\n",
    "        # take the first token in the batch as the embedding\n",
    "        embedding = result.last_hidden_state[:, 0, :]\n",
    "        abstracts_embeddings.append(embedding)\n",
    "    pickle.dump(abstracts_embeddings, open('Data/processed_data/abstracts_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Common authors, delta publication year, common words in titles\n",
    "useful_information_df = information_df[['new_ID','author_representant','pub_year', 'title_lemma']]\n",
    "\n",
    "# prepare data frame for common authors computation\n",
    "common_authors_df = (train_set\n",
    ".merge(useful_information_df, how ='left', left_on = ['node1'], right_on = ['new_ID'])\n",
    ".rename(columns = {'author_representant':'authors_node_1', 'pub_year':'pub_year1', 'title_lemma':'title_lemma1'})\n",
    ".merge(useful_information_df, how ='left', left_on = ['node2'], right_on = ['new_ID'])\n",
    ".rename(columns = {'author_representant':'authors_node_2', 'pub_year':'pub_year2', 'title_lemma':'title_lemma2'})\n",
    ")\n",
    "\n",
    "#  compute common authors\n",
    "train_set['common_authors'] = common_authors_df.apply(lambda x:set(x.authors_node_1)&set(x.authors_node_2),axis = 1)\n",
    "\n",
    "#  compute common words in titles\n",
    "train_set['common_title_words'] = common_authors_df.apply(lambda x:set(x.title_lemma1)&set(x.title_lemma2),axis = 1)\n",
    "\n",
    "# compute delta publication year\n",
    "train_set['delta_publication'] = common_authors_df.apply(lambda x:np.abs(x.pub_year2 - x.pub_year1),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>label</th>\n",
       "      <th>common_authors</th>\n",
       "      <th>common_title_words</th>\n",
       "      <th>delta_publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11515</td>\n",
       "      <td>21190</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7314</td>\n",
       "      <td>16753</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8567</td>\n",
       "      <td>2038</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{brane}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241</td>\n",
       "      <td>27543</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{domain, wall}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11593</td>\n",
       "      <td>2386</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492404</th>\n",
       "      <td>25569</td>\n",
       "      <td>24704</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492405</th>\n",
       "      <td>10240</td>\n",
       "      <td>15360</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492406</th>\n",
       "      <td>2274</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>{y m cho, d k park}</td>\n",
       "      <td>{qed}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492407</th>\n",
       "      <td>5310</td>\n",
       "      <td>22541</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492408</th>\n",
       "      <td>5648</td>\n",
       "      <td>27040</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492409 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        node1  node2  label       common_authors common_title_words  \\\n",
       "0       11515  21190      0                   {}                 {}   \n",
       "1        7314  16753      1                   {}                 {}   \n",
       "2        8567   2038      1                   {}            {brane}   \n",
       "3        3241  27543      1                   {}     {domain, wall}   \n",
       "4       11593   2386      0                   {}                 {}   \n",
       "...       ...    ...    ...                  ...                ...   \n",
       "492404  25569  24704      1                   {}                 {}   \n",
       "492405  10240  15360      0                   {}                 {}   \n",
       "492406   2274   1294      1  {y m cho, d k park}              {qed}   \n",
       "492407   5310  22541      0                   {}                 {}   \n",
       "492408   5648  27040      1                   {}                 {}   \n",
       "\n",
       "        delta_publication  \n",
       "0                       4  \n",
       "1                       7  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       8  \n",
       "...                   ...  \n",
       "492404                  0  \n",
       "492405                  8  \n",
       "492406                  0  \n",
       "492407                  3  \n",
       "492408                  2  \n",
       "\n",
       "[492409 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>label</th>\n",
       "      <th>new_ID_x</th>\n",
       "      <th>authors_node_1</th>\n",
       "      <th>pub_year1</th>\n",
       "      <th>title_lemma1</th>\n",
       "      <th>new_ID_y</th>\n",
       "      <th>authors_node_2</th>\n",
       "      <th>pub_year2</th>\n",
       "      <th>title_lemma2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11515</td>\n",
       "      <td>21190</td>\n",
       "      <td>0</td>\n",
       "      <td>11515</td>\n",
       "      <td>[hssharatch, ra]</td>\n",
       "      <td>1993</td>\n",
       "      <td>[bosonisation, dimension]</td>\n",
       "      <td>21190</td>\n",
       "      <td>[nikita a nekrasov]</td>\n",
       "      <td>1997</td>\n",
       "      <td>[duality, calogero, moser, sutherland, system]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7314</td>\n",
       "      <td>16753</td>\n",
       "      <td>1</td>\n",
       "      <td>7314</td>\n",
       "      <td>[r m ellem, v v bazhanov anu]</td>\n",
       "      <td>2002</td>\n",
       "      <td>[excited, state, tba, phi, perturb, m, model]</td>\n",
       "      <td>16753</td>\n",
       "      <td>[]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[generalize, kdv, quantum, inverse, scatter, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8567</td>\n",
       "      <td>2038</td>\n",
       "      <td>1</td>\n",
       "      <td>8567</td>\n",
       "      <td>[a delgado, g v gersdorff, m quiros]</td>\n",
       "      <td>2002</td>\n",
       "      <td>[brane, assist, scherk, schwarz, supersymmetry...</td>\n",
       "      <td>2038</td>\n",
       "      <td>[max zucker]</td>\n",
       "      <td>2000</td>\n",
       "      <td>[supersymmetric, brane, world, scenario, shell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241</td>\n",
       "      <td>27543</td>\n",
       "      <td>1</td>\n",
       "      <td>3241</td>\n",
       "      <td>[klaus behrndt]</td>\n",
       "      <td>2001</td>\n",
       "      <td>[domain, wall, flow, equation, supergravity]</td>\n",
       "      <td>27543</td>\n",
       "      <td>[martin gremm]</td>\n",
       "      <td>1999</td>\n",
       "      <td>[dimensional, gravity, thick, domain, wall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11593</td>\n",
       "      <td>2386</td>\n",
       "      <td>0</td>\n",
       "      <td>11593</td>\n",
       "      <td>[kenji hamada, asato tsuchiya]</td>\n",
       "      <td>1993</td>\n",
       "      <td>[quantum, gravity, black, hole]</td>\n",
       "      <td>2386</td>\n",
       "      <td>[machiko hatsuda, makoto sakaguchi]</td>\n",
       "      <td>2001</td>\n",
       "      <td>[open, superstring, theory, superalgebra, bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492404</th>\n",
       "      <td>25569</td>\n",
       "      <td>24704</td>\n",
       "      <td>1</td>\n",
       "      <td>25569</td>\n",
       "      <td>[ian i kogan]</td>\n",
       "      <td>1999</td>\n",
       "      <td>[singleton, logarithmic, cft, ad, cft, corresp...</td>\n",
       "      <td>24704</td>\n",
       "      <td>[hong liu imperial college]</td>\n",
       "      <td>1999</td>\n",
       "      <td>[scatter, anti, de, sitter, space, operator, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492405</th>\n",
       "      <td>10240</td>\n",
       "      <td>15360</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>[mahbub majumdar, annechristine davis]</td>\n",
       "      <td>2003</td>\n",
       "      <td>[inflation, tachyon, condensation, large, n, e...</td>\n",
       "      <td>15360</td>\n",
       "      <td>[andrea cappelli, carlo a trugenberger, guille...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[stable, hierarchical, quantum, hall, fluid, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492406</th>\n",
       "      <td>2274</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>2274</td>\n",
       "      <td>[y m cho, d k park]</td>\n",
       "      <td>2000</td>\n",
       "      <td>[non, perturbative, estimate, vacuum, polariza...</td>\n",
       "      <td>1294</td>\n",
       "      <td>[y m cho, d k park]</td>\n",
       "      <td>2000</td>\n",
       "      <td>[effective, action, convergent, series, qed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492407</th>\n",
       "      <td>5310</td>\n",
       "      <td>22541</td>\n",
       "      <td>0</td>\n",
       "      <td>5310</td>\n",
       "      <td>[s deger]</td>\n",
       "      <td>2001</td>\n",
       "      <td>[century, gravity]</td>\n",
       "      <td>22541</td>\n",
       "      <td>[marco billo, frederik denef, pietro fre, igor...</td>\n",
       "      <td>1998</td>\n",
       "      <td>[special, geometry, calabi, yau, compactificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492408</th>\n",
       "      <td>5648</td>\n",
       "      <td>27040</td>\n",
       "      <td>1</td>\n",
       "      <td>5648</td>\n",
       "      <td>[christopher p herzog, igor r klebanov]</td>\n",
       "      <td>2001</td>\n",
       "      <td>[string, tension, supersymmetric, su, m, gauge...</td>\n",
       "      <td>27040</td>\n",
       "      <td>[rc myers]</td>\n",
       "      <td>1999</td>\n",
       "      <td>[dielectric, brane]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492409 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        node1  node2  label  new_ID_x  \\\n",
       "0       11515  21190      0     11515   \n",
       "1        7314  16753      1      7314   \n",
       "2        8567   2038      1      8567   \n",
       "3        3241  27543      1      3241   \n",
       "4       11593   2386      0     11593   \n",
       "...       ...    ...    ...       ...   \n",
       "492404  25569  24704      1     25569   \n",
       "492405  10240  15360      0     10240   \n",
       "492406   2274   1294      1      2274   \n",
       "492407   5310  22541      0      5310   \n",
       "492408   5648  27040      1      5648   \n",
       "\n",
       "                                 authors_node_1  pub_year1  \\\n",
       "0                              [hssharatch, ra]       1993   \n",
       "1                 [r m ellem, v v bazhanov anu]       2002   \n",
       "2          [a delgado, g v gersdorff, m quiros]       2002   \n",
       "3                               [klaus behrndt]       2001   \n",
       "4                [kenji hamada, asato tsuchiya]       1993   \n",
       "...                                         ...        ...   \n",
       "492404                            [ian i kogan]       1999   \n",
       "492405   [mahbub majumdar, annechristine davis]       2003   \n",
       "492406                      [y m cho, d k park]       2000   \n",
       "492407                                [s deger]       2001   \n",
       "492408  [christopher p herzog, igor r klebanov]       2001   \n",
       "\n",
       "                                             title_lemma1  new_ID_y  \\\n",
       "0                               [bosonisation, dimension]     21190   \n",
       "1           [excited, state, tba, phi, perturb, m, model]     16753   \n",
       "2       [brane, assist, scherk, schwarz, supersymmetry...      2038   \n",
       "3            [domain, wall, flow, equation, supergravity]     27543   \n",
       "4                         [quantum, gravity, black, hole]      2386   \n",
       "...                                                   ...       ...   \n",
       "492404  [singleton, logarithmic, cft, ad, cft, corresp...     24704   \n",
       "492405  [inflation, tachyon, condensation, large, n, e...     15360   \n",
       "492406  [non, perturbative, estimate, vacuum, polariza...      1294   \n",
       "492407                                 [century, gravity]     22541   \n",
       "492408  [string, tension, supersymmetric, su, m, gauge...     27040   \n",
       "\n",
       "                                           authors_node_2  pub_year2  \\\n",
       "0                                     [nikita a nekrasov]       1997   \n",
       "1                                                      []       1995   \n",
       "2                                            [max zucker]       2000   \n",
       "3                                          [martin gremm]       1999   \n",
       "4                     [machiko hatsuda, makoto sakaguchi]       2001   \n",
       "...                                                   ...        ...   \n",
       "492404                        [hong liu imperial college]       1999   \n",
       "492405  [andrea cappelli, carlo a trugenberger, guille...       1995   \n",
       "492406                                [y m cho, d k park]       2000   \n",
       "492407  [marco billo, frederik denef, pietro fre, igor...       1998   \n",
       "492408                                         [rc myers]       1999   \n",
       "\n",
       "                                             title_lemma2  \n",
       "0          [duality, calogero, moser, sutherland, system]  \n",
       "1       [generalize, kdv, quantum, inverse, scatter, d...  \n",
       "2       [supersymmetric, brane, world, scenario, shell...  \n",
       "3             [dimensional, gravity, thick, domain, wall]  \n",
       "4       [open, superstring, theory, superalgebra, bran...  \n",
       "...                                                   ...  \n",
       "492404  [scatter, anti, de, sitter, space, operator, p...  \n",
       "492405  [stable, hierarchical, quantum, hall, fluid, w...  \n",
       "492406       [effective, action, convergent, series, qed]  \n",
       "492407  [special, geometry, calabi, yau, compactificat...  \n",
       "492408                                [dielectric, brane]  \n",
       "\n",
       "[492409 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Node2Vec\n",
    "from karateclub import Node2Vec\n",
    "if os.path.isfile('Data/processed_data/articles_node2vec_embeddings.pkl'):\n",
    "    articles_node2vec_embeddings = pickle.load(open('Data/processed_data/articles_node2vec_embeddings.pkl','rb'))\n",
    "else:\n",
    "    node2vec = Node2Vec(walk_length=15) # we leave the defaults parameters for the other values\n",
    "    node2vec.fit(G_articles)\n",
    "    articles_node2vec_embeddings = node2vec.get_embedding()\n",
    "    pickle.dump(articles_node2vec_embeddings, open('Data/processed_data/articles_node2vec_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The node indexing is wrong.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\notebook_tim_explo.ipynb Cell 45'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/notebook_tim_explo.ipynb#ch0000041?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/notebook_tim_explo.ipynb#ch0000041?line=6'>7</a>\u001b[0m     node2vec_authors \u001b[39m=\u001b[39m Node2Vec(walk_length\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/notebook_tim_explo.ipynb#ch0000041?line=7'>8</a>\u001b[0m     node2vec_authors\u001b[39m.\u001b[39;49mfit(G_authors)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/notebook_tim_explo.ipynb#ch0000041?line=8'>9</a>\u001b[0m     authors_node2vec_embeddings \u001b[39m=\u001b[39m node2vec_authors\u001b[39m.\u001b[39mget_embedding()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/notebook_tim_explo.ipynb#ch0000041?line=9'>10</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(authors_node2vec_embeddings, \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mData/processed_data/authors_node2vec_embeddings.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\karateclub\\node_embedding\\neighbourhood\\node2vec.py:69\u001b[0m, in \u001b[0;36mNode2Vec.fit\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=61'>62</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=62'>63</a>\u001b[0m \u001b[39mFitting a DeepWalk model.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=63'>64</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=64'>65</a>\u001b[0m \u001b[39mArg types:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=65'>66</a>\u001b[0m \u001b[39m    * **graph** *(NetworkX graph)* - The graph to be embedded.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=66'>67</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=67'>68</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_seed()\n\u001b[1;32m---> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=68'>69</a>\u001b[0m graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_graph(graph)\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=69'>70</a>\u001b[0m walker \u001b[39m=\u001b[39m BiasedRandomWalker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwalk_length, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwalk_number, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq)\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/node_embedding/neighbourhood/node2vec.py?line=70'>71</a>\u001b[0m walker\u001b[39m.\u001b[39mdo_walks(graph)\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\karateclub\\estimator.py:57\u001b[0m, in \u001b[0;36mEstimator._check_graph\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_graph\u001b[39m(\u001b[39mself\u001b[39m, graph: nx\u001b[39m.\u001b[39mclasses\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mGraph) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m nx\u001b[39m.\u001b[39mclasses\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mGraph:\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=55'>56</a>\u001b[0m     \u001b[39m\"\"\"Check the Karate Club assumptions about the graph.\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=56'>57</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing(graph)\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=57'>58</a>\u001b[0m     graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_integrity(graph)\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=59'>60</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m graph\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\karateclub\\estimator.py:53\u001b[0m, in \u001b[0;36mEstimator._check_indexing\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=49'>50</a>\u001b[0m numeric_indices \u001b[39m=\u001b[39m [index \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(graph\u001b[39m.\u001b[39mnumber_of_nodes())]\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=50'>51</a>\u001b[0m node_indices \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([node \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39mnodes()])\n\u001b[1;32m---> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/karateclub/estimator.py?line=52'>53</a>\u001b[0m \u001b[39massert\u001b[39;00m numeric_indices \u001b[39m==\u001b[39m node_indices, \u001b[39m\"\u001b[39m\u001b[39mThe node indexing is wrong.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The node indexing is wrong."
     ]
    }
   ],
   "source": [
    "### authors embedding leveraging author graphs (random walk for instance)\n",
    "\n",
    "### Node2Vec\n",
    "if os.path.isfile('Data/processed_data/authors_node2vec_embeddings.pkl'):\n",
    "    authors_node2vec_embeddings = pickle.load(open('Data/processed_data/authors_node2vec_embeddings.pkl', 'rb'))\n",
    "else:\n",
    "    node2vec_authors = Node2Vec(walk_length=15)\n",
    "    node2vec_authors.fit(G_authors)\n",
    "    authors_node2vec_embeddings = node2vec_authors.get_embedding()\n",
    "    pickle.dump(authors_node2vec_embeddings, open('Data/processed_data/authors_node2vec_embeddings.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6657d8cf73e4192045730bbde1f7a947d4725a27f96025bfcb1ab47bc67665b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
