{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33631\\AppData\\Local\\Temp\\ipykernel_64480\\934934288.py:26: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "import pickle\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score \n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from link_pred.utils import cosine, euclidian, retrieve_and_pre_processed_informations, compute_unique_names\n",
    "from link_pred.folds_creation import create_and_save_folds\n",
    "from link_pred.create_graphs import create_articles_graph, create_co_authorship_graph, create_authors_co_citation_graph\n",
    "from link_pred.node_embeddings import compute_abstracts_embeddings, compute_titles_embeddings, compute_walklets, compute_node2vec, compute_deep_walks\n",
    "from link_pred.edges_features import Jaccard, AdamicAdar, preferential_attachement, common_journal\n",
    "from link_pred.models_training import get_best_xgb, get_best_MLP, get_best_catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_path = \"Data/raw_data/node_information.csv\"\n",
    "test_set_path = \"Data/raw_data/testing_set.txt\"\n",
    "train_set_path = \"Data/raw_data/training_set.txt\"\n",
    "random_preds_path = \"Data/raw_data/random_predictions.csv\"\n",
    "\n",
    "number_of_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and pre_process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_df = retrieve_and_pre_processed_informations(information_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new id to each node (needs to start from 0)\n",
    "id_old2new = {k: v for v, k in enumerate(list(information_df.ID))}\n",
    "id_new2old = {v: k for v, k in id_old2new.items()}\n",
    "\n",
    "information_df['new_ID'] = information_df.ID.apply(lambda x: id_old2new[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_set = pd.read_csv(train_set_path, sep =\" \", header = None)\n",
    "initial_train_set.columns = ['node1','node2','label']\n",
    "\n",
    "## update nodes values to new indices\n",
    "initial_train_set.node1 = initial_train_set.apply(lambda x:id_old2new[x.node1], axis = 1)\n",
    "initial_train_set.node2 = initial_train_set.apply(lambda x:id_old2new[x.node2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test set\n",
    "\n",
    "test_set = pd.read_csv(test_set_path, sep =\" \", header = None)\n",
    "test_set.columns = ['node1','node2']\n",
    "\n",
    "## update nodes values to new indices\n",
    "test_set.node1 = test_set.apply(lambda x:id_old2new[x.node1], axis = 1)\n",
    "test_set.node2 = test_set.apply(lambda x:id_old2new[x.node2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 already exists !\n",
      "fold 2 already exists !\n",
      "fold 3 already exists !\n",
      "fold 4 already exists !\n",
      "fold 5 already exists !\n"
     ]
    }
   ],
   "source": [
    "create_and_save_folds(initial_train_set, number_of_folds = number_of_folds, validation_size = 0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with authors various names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# convert to lower case, remove punctuation, strip the names\n",
    "authors_raw_set = set([auth.strip().lower().translate(str.maketrans('', '', string.punctuation)) for list_auth in information_df.authors for auth in list_auth if len(auth)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several authors can be named differently (eg. Jean DUPONT, J.Dupont, etc.)\n",
    "# we create a name matcher function to try to indentify each author and assign each denomination a \"representant\"\n",
    "\n",
    "if os.path.isfile('Data/processed_data/representant_dict.pkl'):\n",
    "    representant_dict = pickle.load(open('Data/processed_data/representant_dict.pkl','rb'))\n",
    "else:\n",
    "    representant_dict = compute_unique_names(authors_raw_set)\n",
    "    pickle.dump(representant_dict, open('Data/processed_data/representant_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each name to its representant value\n",
    "information_df.authors = information_df.authors.apply(lambda x: [representant_dict[auth.strip().lower().translate(str.maketrans('', '', string.punctuation))] for auth in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_lemma</th>\n",
       "      <th>new_ID</th>\n",
       "      <th>authors_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>11049</td>\n",
       "      <td>2000</td>\n",
       "      <td>the volume element of space-time and scale inv...</td>\n",
       "      <td>[eiguendelman]</td>\n",
       "      <td>Found.Phys.</td>\n",
       "      <td>gan israel 26-28 june 2000 scale invariance is...</td>\n",
       "      <td>[volume, element, space, time, scale, invariance]</td>\n",
       "      <td>2532</td>\n",
       "      <td>[6178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>302202</td>\n",
       "      <td>2003</td>\n",
       "      <td>bosonization and duality aspects in superfluid...</td>\n",
       "      <td>[nc ribeiro, rf sobreiro, sp sorella]</td>\n",
       "      <td></td>\n",
       "      <td>the bosonization and duality rules in three-di...</td>\n",
       "      <td>[bosonization, duality, aspect, superfluid, su...</td>\n",
       "      <td>9738</td>\n",
       "      <td>[5265, 7124, 1021]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  pub_year                                              title  \\\n",
       "2532   11049      2000  the volume element of space-time and scale inv...   \n",
       "9738  302202      2003  bosonization and duality aspects in superfluid...   \n",
       "\n",
       "                                    authors journal_name  \\\n",
       "2532                         [eiguendelman]  Found.Phys.   \n",
       "9738  [nc ribeiro, rf sobreiro, sp sorella]                \n",
       "\n",
       "                                               abstract  \\\n",
       "2532  gan israel 26-28 june 2000 scale invariance is...   \n",
       "9738  the bosonization and duality rules in three-di...   \n",
       "\n",
       "                                            title_lemma  new_ID  \\\n",
       "2532  [volume, element, space, time, scale, invariance]    2532   \n",
       "9738  [bosonization, duality, aspect, superfluid, su...    9738   \n",
       "\n",
       "              authors_id  \n",
       "2532              [6178]  \n",
       "9738  [5265, 7124, 1021]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique index for each author\n",
    "representants_list = list(set(representant_dict.values()))\n",
    "authors2idx = {k: v for v, k in enumerate(representants_list)}\n",
    "information_df[\"authors_id\"] = information_df.authors.apply(lambda x: [authors2idx[auth] for auth in x])\n",
    "\n",
    "information_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_authors_co_auth = create_co_authorship_graph(information_df, authors2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# those embeddings do not depend on the fold\n",
    "abstracts_embeddings = compute_abstracts_embeddings(information_df)\n",
    "titles_embeddings = compute_titles_embeddings(information_df)\n",
    "\n",
    "\n",
    "if os.path.isfile(f'Data/embeddings/walklets_co_auth_embeddings.pkl'):\n",
    "    walklets_co_auth_embeddings = pickle.load(open('Data/embeddings/walklets_co_auth_embeddings.pkl','rb'))\n",
    "else:\n",
    "    walklets_co_auth_embeddings = compute_walklets(G_authors_co_auth)\n",
    "    pickle.dump(walklets_co_auth_embeddings,open('Data/embeddings/walklets_co_auth_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n"
     ]
    }
   ],
   "source": [
    "# those embeddings depend on the fold\n",
    "for i in range(number_of_folds):\n",
    "    print(f\"fold: {i+1}\")\n",
    "\n",
    "    train_set = pd.read_csv(f\"Data/folds/train_set_{i+1}\")\n",
    "    articles_graph = create_articles_graph(train_set,information_df)\n",
    "    authors_citation_graph = create_authors_co_citation_graph(train_set, information_df, authors2idx)\n",
    "\n",
    "    if os.path.isfile(f'Data/embeddings/articles_walklets_{i+1}.pkl') == False:\n",
    "        walklets_articles_embeddings = compute_walklets(articles_graph)\n",
    "        pickle.dump(walklets_articles_embeddings, open(f'Data/embeddings/articles_walklets_{i+1}.pkl','wb'))\n",
    "    if os.path.isfile(f'Data/embeddings/articles_node2vec_{i+1}.pkl') == False:\n",
    "        node2vec_articles_embeddings = compute_node2vec(articles_graph)\n",
    "        pickle.dump(node2vec_articles_embeddings, open(f'Data/embeddings/articles_node2vec_{i+1}.pkl','wb'))\n",
    "    if os.path.isfile(f'Data/embeddings/co_citation_walklets_{i+1}.pkl') == False:\n",
    "        walklets_co_citation_embeddings = compute_walklets(authors_citation_graph)\n",
    "        pickle.dump(walklets_co_citation_embeddings, open(f'Data/embeddings/co_citation_walklets_{i+1}.pkl','wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_non_embeddings_features(df, information_df, G_articles):\n",
    "    information_df['new_ID'] = information_df.ID.apply(lambda x:id_old2new[x])\n",
    "    useful_information_df = information_df[['new_ID','authors','pub_year', 'title_lemma']]\n",
    "\n",
    "    # prepare data frame for common authors computation\n",
    "    df = (df\n",
    "    .merge(useful_information_df, how ='left', left_on = ['node1'], right_on = ['new_ID'])\n",
    "    .rename(columns = {'authors':'authors_node_1', 'pub_year':'pub_year1', 'title_lemma':'title_lemma1'})\n",
    "    .merge(useful_information_df, how ='left', left_on = ['node2'], right_on = ['new_ID'])\n",
    "    .rename(columns = {'authors':'authors_node_2', 'pub_year':'pub_year2', 'title_lemma':'title_lemma2'})\n",
    "    )\n",
    "\n",
    "    ### Compute page rank\n",
    "    page_rank_dict = nx.pagerank(G_articles)\n",
    "\n",
    "    ### compute degree centrality\n",
    "    centrality_dict = nx.degree_centrality(G_articles)\n",
    "\n",
    "\n",
    "    print('computing resource_allocation')\n",
    "    df['resource_allocation'] = df.apply(lambda x:list(nx.resource_allocation_index(G_articles ,[(x.node1, x.node2)]))[0][2],axis = 1)\n",
    "\n",
    "    print(\"common_journal\")\n",
    "    df['common_journals'] = df.apply(lambda x: common_journal(information_df, x.node1, x.node2),axis = 1)\n",
    "    \n",
    "    print('computing common authors')\n",
    "    #  compute common authors\n",
    "    df['common_authors'] = df.apply(lambda x:len(set(x.authors_node_1)&set(x.authors_node_2)),axis = 1)\n",
    "\n",
    "    print('computing common words')\n",
    "    #  compute common words in titles\n",
    "    df['common_title_words'] = df.apply(lambda x:len(set(x.title_lemma1)&set(x.title_lemma2)),axis = 1)\n",
    "\n",
    "    print('computing delta publication year')\n",
    "    # compute delta publication year\n",
    "    df['delta_publication'] = df.apply(lambda x:x.pub_year2 - x.pub_year1,axis = 1)\n",
    "\n",
    "    # compute edges features\n",
    "    print('computing jacard index')\n",
    "    df['jacard'] = df.apply(lambda x: Jaccard(G_articles, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('computing preferential attachement')\n",
    "    df['pa'] = df.apply(lambda x: preferential_attachement(G_articles, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('computing adamic_adar')\n",
    "    df['adamic_adar'] = df.apply(lambda x: AdamicAdar(G_articles, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('page ranks')\n",
    "    df['page_rank1'] = df.apply(lambda x: page_rank_dict[x.node1],axis = 1)\n",
    "    df['page_rank2'] = df.apply(lambda x: page_rank_dict[x.node2],axis = 1)\n",
    "    \n",
    "    print('compute degree')\n",
    "\n",
    "    df['degree1'] = df.apply(lambda x: centrality_dict[x.node1],axis = 1)\n",
    "    df['degree2'] = df.apply(lambda x: centrality_dict[x.node2],axis = 1)\n",
    "\n",
    "    \n",
    "    df = df.fillna({ 'jacard':df.jacard.mean(),\n",
    "                     'adamic_adar':df.adamic_adar.mean()\n",
    "                     })\n",
    "\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_features(df,\n",
    "                                information_df,\n",
    "                                abstracts_embeddings,\n",
    "                                titles_embeddings,\n",
    "                                walklets_articles_embeddings,\n",
    "                                walklets_co_auth_embeddings,\n",
    "                                walklets_co_citation_embeddings,\n",
    "                                node2vec_articles_embeddings,\n",
    "                                pca = True):\n",
    "\n",
    "    # for each article take a mean of the authors embedding as global autors embedding (idem for citation)\n",
    "    articles_authors_embedding = []\n",
    "    articles_authors_embedding_citation = []\n",
    "    for i in range(information_df.shape[0]):\n",
    "        value = information_df[information_df.new_ID == i]\n",
    "        authors_id = value.authors_id\n",
    "        embeddings = np.array([0 for i in range(128)]).astype('float64')\n",
    "        embeddings_citation = np.array([0 for i in range(128)]).astype('float64')\n",
    "        for author in authors_id:\n",
    "            embeddings+=walklets_co_auth_embeddings[author][0]\n",
    "            embeddings_citation+=walklets_co_citation_embeddings[author][0]\n",
    "        articles_authors_embedding.append(embeddings/len(authors_id))\n",
    "        articles_authors_embedding_citation.append(embeddings_citation/len(authors_id))\n",
    "\n",
    "\n",
    "    # compute some cosine and euclidian based distances\n",
    "    df['articles_walklets_cosine'] = df.apply(lambda x:cosine(walklets_articles_embeddings[x.node1],walklets_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['articles_node2vec_cosine'] = df.apply(lambda x:cosine(node2vec_articles_embeddings[x.node1],node2vec_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['abstracts_embeddings_cosine'] = df.apply(lambda x:cosine(abstracts_embeddings[x.node1][0],abstracts_embeddings[x.node2][0]), axis = 1)\n",
    "    \n",
    "    df['articles_walklets_euclidian'] = df.apply(lambda x:euclidian(walklets_articles_embeddings[x.node1],walklets_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['articles_node2vec_euclidian'] = df.apply(lambda x:euclidian(node2vec_articles_embeddings[x.node1],node2vec_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['abstracts_embeddings_euclidian'] = df.apply(lambda x:euclidian(abstracts_embeddings[x.node1][0],abstracts_embeddings[x.node2][0]), axis = 1)\n",
    "\n",
    "    df['title_embeddings_cosine'] = df.apply(lambda x:cosine(titles_embeddings[x.node1][0],titles_embeddings[x.node2][0]), axis = 1)\n",
    "    df['title_embeddings_euclidian'] = df.apply(lambda x:euclidian(titles_embeddings[x.node1][0],titles_embeddings[x.node2][0]), axis = 1)\n",
    "    \n",
    "    # compute some cosine and euclidian based distances for authors\n",
    "    df['co_authorship_embeddings_cosine'] = df.apply(lambda x:cosine(articles_authors_embedding[x.node1],articles_authors_embedding[x.node2]), axis = 1)\n",
    "    df['authors_embeddings_cosine_citation'] = df.apply(lambda x:cosine(articles_authors_embedding_citation[x.node1],articles_authors_embedding_citation[x.node2]), axis = 1)    \n",
    "    df['co_authorship_embeddings_euclidian'] = df.apply(lambda x:euclidian(articles_authors_embedding[x.node1],articles_authors_embedding[x.node2]), axis = 1)\n",
    "    df['authors_embeddings_euclidian_citation'] = df.apply(lambda x:euclidian(articles_authors_embedding_citation[x.node1],articles_authors_embedding_citation[x.node2]), axis = 1)\n",
    "    \n",
    "    # node1 and node2 article embedding\n",
    "    print(\"add articles walklets embeddings\")\n",
    "    # only append vectors of size 10 that represent articles embeddings (quicker to compute)\n",
    "    if pca:\n",
    "        pca_walklets= PCA(n_components = 10)\n",
    "        walklets_articles_embeddings = pca_walklets.fit_transform(walklets_articles_embeddings)\n",
    "        pca_node2vec =  PCA(n_components = 10)\n",
    "        node2vec_articles_embeddings = pca_node2vec.fit_transform(node2vec_articles_embeddings)\n",
    "\n",
    "\n",
    "    walklets_node_embeddings_df = pd.DataFrame(walklets_articles_embeddings, columns = [f'emb_walklets_{i}' for i in range(len(walklets_articles_embeddings[0]))])\n",
    "    walklets_node_embeddings_df = walklets_node_embeddings_df.reset_index().rename(columns = {'index':'node'})\n",
    "    df = (df\n",
    "        .merge(walklets_node_embeddings_df, how ='left', left_on = ['node1'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "        .merge(walklets_node_embeddings_df, how ='left', left_on = ['node2'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "    )\n",
    "\n",
    "    print(\"add articles node2vecs embeddings\")\n",
    "    # only append vectors of size 10 that represent articles embeddings (quicker to compute)\n",
    "\n",
    "    node_node2vec_embeddings_df = pd.DataFrame(node2vec_articles_embeddings, columns = [f'emb_node2vec{i}' for i in range(len(node2vec_articles_embeddings[0]))])\n",
    "    node_node2vec_embeddings_df = node_node2vec_embeddings_df.reset_index().rename(columns = {'index':'node'})\n",
    "    df = (df\n",
    "        .merge(node_node2vec_embeddings_df, how ='left', left_on = ['node1'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "        .merge(node_node2vec_embeddings_df, how ='left', left_on = ['node2'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compute features for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_folds):\n",
    "    print(f\"fold: {i+1}\")\n",
    "    if os.path.isfile(f\"Data/processed_data/train_set_features{i+1}.csv\") and os.path.isfile(f\"Data/processed_data/val_set_features{i+1}.csv\") and os.path.isfile(f\"Data/processed_data/test_set_features{i+1}.csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        # load sets\n",
    "        train_set = pd.read_csv(f\"Data/folds/train_set_{i+1}\")\n",
    "        validation_set = pd.read_csv(f\"Data/folds/validation_set_{i+1}\")\n",
    "\n",
    "        # compute graphs\n",
    "        G_articles = create_articles_graph(train_set,information_df)\n",
    "\n",
    "        # load embeddings\n",
    "        walklets_articles_embeddings = pickle.load(open(f'Data/embeddings/articles_walklets_{i+1}.pkl','rb'))\n",
    "        walklets_co_citation_embeddings = pickle.load(open(f'Data/embeddings/co_citation_walklets_{i+1}.pkl','rb'))\n",
    "        node2vec_articles_embeddings = pickle.load(open(f'Data/embeddings/articles_node2vec_{i+1}.pkl','rb'))\n",
    "\n",
    "        # compute features for train\n",
    "        print(\"compute train features\")\n",
    "        train_set_with_features = compute_non_embeddings_features(train_set, information_df, G_articles)\n",
    "        train_set_with_features = compute_embedding_features(train_set_with_features, information_df, abstracts_embeddings,titles_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True)\n",
    "        # compute features for val\n",
    "        print(\"compute validation features\")\n",
    "        val_set_with_features = compute_non_embeddings_features(validation_set, information_df, G_articles)\n",
    "        val_set_with_features = compute_embedding_features(val_set_with_features, information_df, abstracts_embeddings,titles_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True)\n",
    "\n",
    "        # compute features for test\n",
    "        print(\"compute test features\")\n",
    "        test_set_with_features = compute_non_embeddings_features(test_set, information_df, G_articles)\n",
    "        test_set_with_features = compute_embedding_features(test_set_with_features, information_df, abstracts_embeddings,titles_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True)\n",
    "\n",
    "        train_set_with_features.to_csv(f\"Data/processed_data/train_set_features{i+1}.csv\", index = False)\n",
    "        val_set_with_features.to_csv(f\"Data/processed_data/val_set_features{i+1}.csv\", index = False)\n",
    "        test_set_with_features.to_csv(f\"Data/processed_data/test_set_features{i+1}.csv\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute columns of interest\n",
    "all_columns = set(pd.read_csv(\"Data/processed_data/train_set_features1.csv\").columns)\n",
    "\n",
    "to_remove = set(['node1', 'node2', 'label', 'new_ID_x', 'authors_node_1',\n",
    "       'title_lemma1', 'new_ID_y', 'authors_node_2', 'title_lemma2','resource_allocation','pub_year2', 'pub_year1'])\n",
    "columns_to_keep= list(all_columns-to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n",
      "train cat\n",
      " depth  |   L2    | learning_rate |    Thresh    |    F1     \n",
      "0:\tlearn: 0.9825325\ttotal: 69.5ms\tremaining: 625ms\n",
      "1:\tlearn: 0.9825325\ttotal: 123ms\tremaining: 491ms\n",
      "2:\tlearn: 0.9829920\ttotal: 174ms\tremaining: 407ms\n",
      "3:\tlearn: 0.9827163\ttotal: 224ms\tremaining: 336ms\n",
      "4:\tlearn: 0.9828544\ttotal: 275ms\tremaining: 275ms\n",
      "5:\tlearn: 0.9831667\ttotal: 324ms\tremaining: 216ms\n",
      "6:\tlearn: 0.9830907\ttotal: 370ms\tremaining: 159ms\n",
      "7:\tlearn: 0.9830907\ttotal: 418ms\tremaining: 105ms\n",
      "8:\tlearn: 0.9832593\ttotal: 463ms\tremaining: 51.5ms\n",
      "9:\tlearn: 0.9832335\ttotal: 506ms\tremaining: 0us\n",
      "   3    |    1    |  0.03   | 0.45620550719916175 | 0.97163707493229 \n",
      "0:\tlearn: 0.9825325\ttotal: 51.1ms\tremaining: 460ms\n",
      "1:\tlearn: 0.9825325\ttotal: 102ms\tremaining: 408ms\n",
      "2:\tlearn: 0.9829920\ttotal: 153ms\tremaining: 358ms\n",
      "3:\tlearn: 0.9827163\ttotal: 204ms\tremaining: 306ms\n",
      "4:\tlearn: 0.9828544\ttotal: 254ms\tremaining: 254ms\n",
      "5:\tlearn: 0.9831667\ttotal: 303ms\tremaining: 202ms\n",
      "6:\tlearn: 0.9830907\ttotal: 352ms\tremaining: 151ms\n",
      "7:\tlearn: 0.9830907\ttotal: 400ms\tremaining: 99.9ms\n",
      "8:\tlearn: 0.9832593\ttotal: 444ms\tremaining: 49.4ms\n",
      "9:\tlearn: 0.9832335\ttotal: 491ms\tremaining: 0us\n",
      "   3    |    3    |  0.03   | 0.4562016071722662 | 0.97163707493229 \n",
      "0:\tlearn: 0.9825325\ttotal: 54ms\tremaining: 486ms\n",
      "1:\tlearn: 0.9825325\ttotal: 102ms\tremaining: 407ms\n",
      "2:\tlearn: 0.9829920\ttotal: 150ms\tremaining: 350ms\n",
      "3:\tlearn: 0.9827163\ttotal: 198ms\tremaining: 297ms\n",
      "4:\tlearn: 0.9828544\ttotal: 245ms\tremaining: 245ms\n",
      "5:\tlearn: 0.9831667\ttotal: 291ms\tremaining: 194ms\n",
      "6:\tlearn: 0.9830907\ttotal: 338ms\tremaining: 145ms\n",
      "7:\tlearn: 0.9830907\ttotal: 383ms\tremaining: 95.8ms\n",
      "8:\tlearn: 0.9832593\ttotal: 428ms\tremaining: 47.5ms\n",
      "9:\tlearn: 0.9832335\ttotal: 471ms\tremaining: 0us\n",
      "   3    |    5    |  0.03   | 0.45620577105188626 | 0.97163707493229 \n",
      "0:\tlearn: 0.9825325\ttotal: 50.4ms\tremaining: 453ms\n",
      "1:\tlearn: 0.9825325\ttotal: 97.9ms\tremaining: 392ms\n",
      "2:\tlearn: 0.9829920\ttotal: 144ms\tremaining: 337ms\n",
      "3:\tlearn: 0.9827163\ttotal: 192ms\tremaining: 288ms\n",
      "4:\tlearn: 0.9828544\ttotal: 238ms\tremaining: 238ms\n",
      "5:\tlearn: 0.9831667\ttotal: 285ms\tremaining: 190ms\n",
      "6:\tlearn: 0.9830907\ttotal: 331ms\tremaining: 142ms\n",
      "7:\tlearn: 0.9830907\ttotal: 377ms\tremaining: 94.3ms\n",
      "8:\tlearn: 0.9832593\ttotal: 422ms\tremaining: 46.8ms\n",
      "9:\tlearn: 0.9832335\ttotal: 467ms\tremaining: 0us\n",
      "   3    |    7    |  0.03   | 0.456200980580768 | 0.97163707493229 \n",
      "0:\tlearn: 0.9825325\ttotal: 54.1ms\tremaining: 487ms\n",
      "1:\tlearn: 0.9825325\ttotal: 105ms\tremaining: 422ms\n",
      "2:\tlearn: 0.9829920\ttotal: 154ms\tremaining: 360ms\n",
      "3:\tlearn: 0.9827163\ttotal: 205ms\tremaining: 307ms\n",
      "4:\tlearn: 0.9828544\ttotal: 253ms\tremaining: 253ms\n",
      "5:\tlearn: 0.9831667\ttotal: 301ms\tremaining: 201ms\n",
      "6:\tlearn: 0.9830907\ttotal: 349ms\tremaining: 150ms\n",
      "7:\tlearn: 0.9830907\ttotal: 396ms\tremaining: 99ms\n",
      "8:\tlearn: 0.9832593\ttotal: 441ms\tremaining: 49ms\n",
      "9:\tlearn: 0.9832335\ttotal: 487ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.97163707493229 \n",
      "0:\tlearn: 0.9825325\ttotal: 53.3ms\tremaining: 480ms\n",
      "1:\tlearn: 0.9812748\ttotal: 103ms\tremaining: 412ms\n",
      "2:\tlearn: 0.9829203\ttotal: 152ms\tremaining: 355ms\n",
      "3:\tlearn: 0.9829190\ttotal: 201ms\tremaining: 302ms\n",
      "4:\tlearn: 0.9845664\ttotal: 250ms\tremaining: 250ms\n",
      "5:\tlearn: 0.9846089\ttotal: 298ms\tremaining: 199ms\n",
      "6:\tlearn: 0.9848793\ttotal: 346ms\tremaining: 148ms\n",
      "7:\tlearn: 0.9851963\ttotal: 391ms\tremaining: 97.9ms\n",
      "8:\tlearn: 0.9854807\ttotal: 437ms\tremaining: 48.6ms\n",
      "9:\tlearn: 0.9856087\ttotal: 485ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.9714371617558629 \n",
      "0:\tlearn: 0.9825325\ttotal: 53.2ms\tremaining: 478ms\n",
      "1:\tlearn: 0.9812748\ttotal: 102ms\tremaining: 406ms\n",
      "2:\tlearn: 0.9829203\ttotal: 150ms\tremaining: 349ms\n",
      "3:\tlearn: 0.9827958\ttotal: 197ms\tremaining: 295ms\n",
      "4:\tlearn: 0.9841574\ttotal: 243ms\tremaining: 243ms\n",
      "5:\tlearn: 0.9840719\ttotal: 288ms\tremaining: 192ms\n",
      "6:\tlearn: 0.9846003\ttotal: 335ms\tremaining: 144ms\n",
      "7:\tlearn: 0.9847448\ttotal: 380ms\tremaining: 95ms\n",
      "8:\tlearn: 0.9853927\ttotal: 424ms\tremaining: 47.1ms\n",
      "9:\tlearn: 0.9853992\ttotal: 469ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.9715657588716332 \n",
      "0:\tlearn: 0.9825325\ttotal: 49.9ms\tremaining: 449ms\n",
      "1:\tlearn: 0.9812748\ttotal: 97.7ms\tremaining: 391ms\n",
      "2:\tlearn: 0.9829203\ttotal: 144ms\tremaining: 336ms\n",
      "3:\tlearn: 0.9829190\ttotal: 192ms\tremaining: 288ms\n",
      "4:\tlearn: 0.9845664\ttotal: 239ms\tremaining: 239ms\n",
      "5:\tlearn: 0.9846089\ttotal: 285ms\tremaining: 190ms\n",
      "6:\tlearn: 0.9848793\ttotal: 333ms\tremaining: 143ms\n",
      "7:\tlearn: 0.9851963\ttotal: 380ms\tremaining: 95ms\n",
      "8:\tlearn: 0.9854807\ttotal: 425ms\tremaining: 47.3ms\n",
      "9:\tlearn: 0.9856087\ttotal: 472ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.9714371617558629 \n",
      "0:\tlearn: 0.9825325\ttotal: 51.3ms\tremaining: 462ms\n",
      "1:\tlearn: 0.9812748\ttotal: 102ms\tremaining: 409ms\n",
      "2:\tlearn: 0.9829203\ttotal: 151ms\tremaining: 352ms\n",
      "3:\tlearn: 0.9829190\ttotal: 206ms\tremaining: 308ms\n",
      "4:\tlearn: 0.9845664\ttotal: 253ms\tremaining: 253ms\n",
      "5:\tlearn: 0.9846089\ttotal: 301ms\tremaining: 200ms\n",
      "6:\tlearn: 0.9848793\ttotal: 348ms\tremaining: 149ms\n",
      "7:\tlearn: 0.9851963\ttotal: 393ms\tremaining: 98.3ms\n",
      "8:\tlearn: 0.9854807\ttotal: 490ms\tremaining: 54.5ms\n",
      "9:\tlearn: 0.9856087\ttotal: 541ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.9714371617558629 \n",
      "0:\tlearn: 0.9825325\ttotal: 54.3ms\tremaining: 489ms\n",
      "1:\tlearn: 0.9812748\ttotal: 103ms\tremaining: 412ms\n",
      "2:\tlearn: 0.9829203\ttotal: 151ms\tremaining: 351ms\n",
      "3:\tlearn: 0.9829190\ttotal: 198ms\tremaining: 297ms\n",
      "4:\tlearn: 0.9845664\ttotal: 248ms\tremaining: 248ms\n",
      "5:\tlearn: 0.9846089\ttotal: 295ms\tremaining: 197ms\n",
      "6:\tlearn: 0.9848793\ttotal: 343ms\tremaining: 147ms\n",
      "7:\tlearn: 0.9851963\ttotal: 390ms\tremaining: 97.6ms\n",
      "8:\tlearn: 0.9854807\ttotal: 437ms\tremaining: 48.6ms\n",
      "9:\tlearn: 0.9856087\ttotal: 483ms\tremaining: 0us\n",
      "   3    |    9    |  0.03   | 0.4562019204680672 | 0.9714371617558629 \n",
      "0:\tlearn: 0.9839089\ttotal: 63.5ms\tremaining: 571ms\n",
      "1:\tlearn: 0.9841385\ttotal: 123ms\tremaining: 492ms\n",
      "2:\tlearn: 0.9844982\ttotal: 182ms\tremaining: 425ms\n",
      "3:\tlearn: 0.9844986\ttotal: 246ms\tremaining: 369ms\n",
      "4:\tlearn: 0.9842800\ttotal: 309ms\tremaining: 309ms\n",
      "5:\tlearn: 0.9843278\ttotal: 369ms\tremaining: 246ms\n",
      "6:\tlearn: 0.9853512\ttotal: 425ms\tremaining: 182ms\n",
      "7:\tlearn: 0.9847567\ttotal: 480ms\tremaining: 120ms\n",
      "8:\tlearn: 0.9854019\ttotal: 534ms\tremaining: 59.3ms\n",
      "9:\tlearn: 0.9855655\ttotal: 590ms\tremaining: 0us\n",
      "   5    |    1    |  0.03   | 0.430932445065969 | 0.972650086407694 \n",
      "0:\tlearn: 0.9839089\ttotal: 66.2ms\tremaining: 596ms\n",
      "1:\tlearn: 0.9841385\ttotal: 129ms\tremaining: 515ms\n",
      "2:\tlearn: 0.9844967\ttotal: 190ms\tremaining: 442ms\n",
      "3:\tlearn: 0.9844986\ttotal: 252ms\tremaining: 378ms\n",
      "4:\tlearn: 0.9842800\ttotal: 311ms\tremaining: 311ms\n",
      "5:\tlearn: 0.9843200\ttotal: 368ms\tremaining: 246ms\n",
      "6:\tlearn: 0.9853481\ttotal: 425ms\tremaining: 182ms\n",
      "7:\tlearn: 0.9847521\ttotal: 481ms\tremaining: 120ms\n",
      "8:\tlearn: 0.9854019\ttotal: 539ms\tremaining: 59.9ms\n",
      "9:\tlearn: 0.9855655\ttotal: 597ms\tremaining: 0us\n",
      "   5    |    3    |  0.03   | 0.4309340095239809 | 0.9727272727272727 \n",
      "0:\tlearn: 0.9839089\ttotal: 67.5ms\tremaining: 608ms\n",
      "1:\tlearn: 0.9841385\ttotal: 130ms\tremaining: 520ms\n",
      "2:\tlearn: 0.9844967\ttotal: 193ms\tremaining: 451ms\n",
      "3:\tlearn: 0.9844986\ttotal: 256ms\tremaining: 385ms\n",
      "4:\tlearn: 0.9842800\ttotal: 317ms\tremaining: 317ms\n",
      "5:\tlearn: 0.9843185\ttotal: 377ms\tremaining: 251ms\n",
      "6:\tlearn: 0.9853465\ttotal: 435ms\tremaining: 186ms\n",
      "7:\tlearn: 0.9847430\ttotal: 492ms\tremaining: 123ms\n",
      "8:\tlearn: 0.9853989\ttotal: 555ms\tremaining: 61.7ms\n",
      "9:\tlearn: 0.9855624\ttotal: 654ms\tremaining: 0us\n",
      "   5    |    5    |  0.03   | 0.43093574070686225 | 0.9727272727272727 \n",
      "0:\tlearn: 0.9839089\ttotal: 69ms\tremaining: 621ms\n",
      "1:\tlearn: 0.9841385\ttotal: 131ms\tremaining: 523ms\n",
      "2:\tlearn: 0.9844967\ttotal: 191ms\tremaining: 445ms\n",
      "3:\tlearn: 0.9844986\ttotal: 252ms\tremaining: 378ms\n",
      "4:\tlearn: 0.9842753\ttotal: 313ms\tremaining: 313ms\n",
      "5:\tlearn: 0.9843185\ttotal: 371ms\tremaining: 247ms\n",
      "6:\tlearn: 0.9853465\ttotal: 429ms\tremaining: 184ms\n",
      "7:\tlearn: 0.9847414\ttotal: 484ms\tremaining: 121ms\n",
      "8:\tlearn: 0.9853897\ttotal: 540ms\tremaining: 60ms\n",
      "9:\tlearn: 0.9855683\ttotal: 596ms\tremaining: 0us\n",
      "   5    |    7    |  0.03   | 0.43093978729633464 | 0.9727272727272727 \n",
      "0:\tlearn: 0.9839089\ttotal: 61.9ms\tremaining: 557ms\n",
      "1:\tlearn: 0.9841369\ttotal: 121ms\tremaining: 486ms\n",
      "2:\tlearn: 0.9844967\ttotal: 183ms\tremaining: 427ms\n",
      "3:\tlearn: 0.9844986\ttotal: 244ms\tremaining: 366ms\n",
      "4:\tlearn: 0.9842753\ttotal: 303ms\tremaining: 303ms\n",
      "5:\tlearn: 0.9843139\ttotal: 362ms\tremaining: 242ms\n",
      "6:\tlearn: 0.9853465\ttotal: 418ms\tremaining: 179ms\n",
      "7:\tlearn: 0.9847414\ttotal: 475ms\tremaining: 119ms\n",
      "8:\tlearn: 0.9853881\ttotal: 532ms\tremaining: 59.1ms\n",
      "9:\tlearn: 0.9855683\ttotal: 590ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9727272727272727 \n",
      "0:\tlearn: 0.9839089\ttotal: 64.3ms\tremaining: 579ms\n",
      "1:\tlearn: 0.9843825\ttotal: 127ms\tremaining: 507ms\n",
      "2:\tlearn: 0.9845473\ttotal: 190ms\tremaining: 444ms\n",
      "3:\tlearn: 0.9846737\ttotal: 251ms\tremaining: 376ms\n",
      "4:\tlearn: 0.9852961\ttotal: 309ms\tremaining: 309ms\n",
      "5:\tlearn: 0.9862323\ttotal: 366ms\tremaining: 244ms\n",
      "6:\tlearn: 0.9868452\ttotal: 424ms\tremaining: 182ms\n",
      "7:\tlearn: 0.9869852\ttotal: 478ms\tremaining: 120ms\n",
      "8:\tlearn: 0.9872882\ttotal: 534ms\tremaining: 59.4ms\n",
      "9:\tlearn: 0.9876401\ttotal: 591ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9721262208865515 \n",
      "0:\tlearn: 0.9839089\ttotal: 65.3ms\tremaining: 588ms\n",
      "1:\tlearn: 0.9843825\ttotal: 128ms\tremaining: 513ms\n",
      "2:\tlearn: 0.9845458\ttotal: 191ms\tremaining: 445ms\n",
      "3:\tlearn: 0.9846690\ttotal: 252ms\tremaining: 378ms\n",
      "4:\tlearn: 0.9852914\ttotal: 311ms\tremaining: 311ms\n",
      "5:\tlearn: 0.9862307\ttotal: 371ms\tremaining: 247ms\n",
      "6:\tlearn: 0.9868437\ttotal: 430ms\tremaining: 184ms\n",
      "7:\tlearn: 0.9869836\ttotal: 485ms\tremaining: 121ms\n",
      "8:\tlearn: 0.9872882\ttotal: 540ms\tremaining: 60ms\n",
      "9:\tlearn: 0.9876338\ttotal: 596ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9721262208865515 \n",
      "0:\tlearn: 0.9839089\ttotal: 64.3ms\tremaining: 579ms\n",
      "1:\tlearn: 0.9843825\ttotal: 124ms\tremaining: 498ms\n",
      "2:\tlearn: 0.9845350\ttotal: 185ms\tremaining: 431ms\n",
      "3:\tlearn: 0.9846690\ttotal: 244ms\tremaining: 366ms\n",
      "4:\tlearn: 0.9852914\ttotal: 303ms\tremaining: 303ms\n",
      "5:\tlearn: 0.9862292\ttotal: 359ms\tremaining: 239ms\n",
      "6:\tlearn: 0.9868437\ttotal: 417ms\tremaining: 179ms\n",
      "7:\tlearn: 0.9869821\ttotal: 472ms\tremaining: 118ms\n",
      "8:\tlearn: 0.9872866\ttotal: 529ms\tremaining: 58.8ms\n",
      "9:\tlearn: 0.9876306\ttotal: 586ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9721262208865515 \n",
      "0:\tlearn: 0.9839089\ttotal: 64.7ms\tremaining: 582ms\n",
      "1:\tlearn: 0.9843825\ttotal: 127ms\tremaining: 507ms\n",
      "2:\tlearn: 0.9845350\ttotal: 190ms\tremaining: 443ms\n",
      "3:\tlearn: 0.9846674\ttotal: 252ms\tremaining: 378ms\n",
      "4:\tlearn: 0.9852914\ttotal: 310ms\tremaining: 310ms\n",
      "5:\tlearn: 0.9862292\ttotal: 369ms\tremaining: 246ms\n",
      "6:\tlearn: 0.9868452\ttotal: 430ms\tremaining: 184ms\n",
      "7:\tlearn: 0.9869821\ttotal: 487ms\tremaining: 122ms\n",
      "8:\tlearn: 0.9872866\ttotal: 544ms\tremaining: 60.4ms\n",
      "9:\tlearn: 0.9876306\ttotal: 601ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720918003230289 \n",
      "0:\tlearn: 0.9839089\ttotal: 65.9ms\tremaining: 593ms\n",
      "1:\tlearn: 0.9843809\ttotal: 129ms\tremaining: 517ms\n",
      "2:\tlearn: 0.9845350\ttotal: 192ms\tremaining: 449ms\n",
      "3:\tlearn: 0.9846644\ttotal: 255ms\tremaining: 383ms\n",
      "4:\tlearn: 0.9852898\ttotal: 313ms\tremaining: 313ms\n",
      "5:\tlearn: 0.9862276\ttotal: 374ms\tremaining: 249ms\n",
      "6:\tlearn: 0.9868452\ttotal: 434ms\tremaining: 186ms\n",
      "7:\tlearn: 0.9869821\ttotal: 492ms\tremaining: 123ms\n",
      "8:\tlearn: 0.9872835\ttotal: 549ms\tremaining: 61ms\n",
      "9:\tlearn: 0.9876378\ttotal: 608ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720918003230289 \n",
      "0:\tlearn: 0.9865090\ttotal: 87.2ms\tremaining: 784ms\n",
      "1:\tlearn: 0.9868498\ttotal: 172ms\tremaining: 687ms\n",
      "2:\tlearn: 0.9872146\ttotal: 254ms\tremaining: 594ms\n",
      "3:\tlearn: 0.9873891\ttotal: 337ms\tremaining: 505ms\n",
      "4:\tlearn: 0.9876170\ttotal: 417ms\tremaining: 417ms\n",
      "5:\tlearn: 0.9876798\ttotal: 493ms\tremaining: 329ms\n",
      "6:\tlearn: 0.9878076\ttotal: 572ms\tremaining: 245ms\n",
      "7:\tlearn: 0.9878849\ttotal: 648ms\tremaining: 162ms\n",
      "8:\tlearn: 0.9880143\ttotal: 723ms\tremaining: 80.3ms\n",
      "9:\tlearn: 0.9880520\ttotal: 794ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9717992949823746 \n",
      "0:\tlearn: 0.9865090\ttotal: 81.2ms\tremaining: 731ms\n",
      "1:\tlearn: 0.9868483\ttotal: 157ms\tremaining: 630ms\n",
      "2:\tlearn: 0.9871841\ttotal: 235ms\tremaining: 547ms\n",
      "3:\tlearn: 0.9873603\ttotal: 308ms\tremaining: 462ms\n",
      "4:\tlearn: 0.9876141\ttotal: 391ms\tremaining: 391ms\n",
      "5:\tlearn: 0.9874319\ttotal: 470ms\tremaining: 313ms\n",
      "6:\tlearn: 0.9874202\ttotal: 540ms\tremaining: 231ms\n",
      "7:\tlearn: 0.9874523\ttotal: 611ms\tremaining: 153ms\n",
      "8:\tlearn: 0.9877287\ttotal: 680ms\tremaining: 75.6ms\n",
      "9:\tlearn: 0.9877969\ttotal: 751ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720837861130888 \n",
      "0:\tlearn: 0.9865090\ttotal: 82.6ms\tremaining: 743ms\n",
      "1:\tlearn: 0.9870296\ttotal: 161ms\tremaining: 642ms\n",
      "2:\tlearn: 0.9872900\ttotal: 238ms\tremaining: 555ms\n",
      "3:\tlearn: 0.9874809\ttotal: 313ms\tremaining: 469ms\n",
      "4:\tlearn: 0.9876919\ttotal: 446ms\tremaining: 446ms\n",
      "5:\tlearn: 0.9875109\ttotal: 519ms\tremaining: 346ms\n",
      "6:\tlearn: 0.9874939\ttotal: 592ms\tremaining: 254ms\n",
      "7:\tlearn: 0.9875395\ttotal: 660ms\tremaining: 165ms\n",
      "8:\tlearn: 0.9877736\ttotal: 729ms\tremaining: 80.9ms\n",
      "9:\tlearn: 0.9878361\ttotal: 800ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720198737345437 \n",
      "0:\tlearn: 0.9865090\ttotal: 85.1ms\tremaining: 766ms\n",
      "1:\tlearn: 0.9870296\ttotal: 164ms\tremaining: 655ms\n",
      "2:\tlearn: 0.9872885\ttotal: 244ms\tremaining: 568ms\n",
      "3:\tlearn: 0.9874794\ttotal: 322ms\tremaining: 483ms\n",
      "4:\tlearn: 0.9876919\ttotal: 397ms\tremaining: 397ms\n",
      "5:\tlearn: 0.9875109\ttotal: 472ms\tremaining: 314ms\n",
      "6:\tlearn: 0.9874861\ttotal: 546ms\tremaining: 234ms\n",
      "7:\tlearn: 0.9875364\ttotal: 660ms\tremaining: 165ms\n",
      "8:\tlearn: 0.9877705\ttotal: 729ms\tremaining: 81ms\n",
      "9:\tlearn: 0.9878330\ttotal: 798ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720198737345437 \n",
      "0:\tlearn: 0.9865090\ttotal: 84.3ms\tremaining: 758ms\n",
      "1:\tlearn: 0.9870281\ttotal: 169ms\tremaining: 675ms\n",
      "2:\tlearn: 0.9872885\ttotal: 250ms\tremaining: 584ms\n",
      "3:\tlearn: 0.9874794\ttotal: 329ms\tremaining: 494ms\n",
      "4:\tlearn: 0.9876887\ttotal: 409ms\tremaining: 409ms\n",
      "5:\tlearn: 0.9875108\ttotal: 487ms\tremaining: 324ms\n",
      "6:\tlearn: 0.9874830\ttotal: 563ms\tremaining: 241ms\n",
      "7:\tlearn: 0.9875364\ttotal: 638ms\tremaining: 159ms\n",
      "8:\tlearn: 0.9877674\ttotal: 713ms\tremaining: 79.2ms\n",
      "9:\tlearn: 0.9878268\ttotal: 791ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720695457094785 \n",
      "0:\tlearn: 0.9865090\ttotal: 87.8ms\tremaining: 790ms\n",
      "1:\tlearn: 0.9872230\ttotal: 169ms\tremaining: 675ms\n",
      "2:\tlearn: 0.9879884\ttotal: 249ms\tremaining: 582ms\n",
      "3:\tlearn: 0.9882221\ttotal: 329ms\tremaining: 493ms\n",
      "4:\tlearn: 0.9884626\ttotal: 457ms\tremaining: 457ms\n",
      "5:\tlearn: 0.9885821\ttotal: 534ms\tremaining: 356ms\n",
      "6:\tlearn: 0.9887912\ttotal: 611ms\tremaining: 262ms\n",
      "7:\tlearn: 0.9887925\ttotal: 684ms\tremaining: 171ms\n",
      "8:\tlearn: 0.9889408\ttotal: 765ms\tremaining: 85ms\n",
      "9:\tlearn: 0.9890240\ttotal: 840ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.971357969223857 \n",
      "0:\tlearn: 0.9865090\ttotal: 89ms\tremaining: 801ms\n",
      "1:\tlearn: 0.9872215\ttotal: 174ms\tremaining: 696ms\n",
      "2:\tlearn: 0.9880481\ttotal: 257ms\tremaining: 600ms\n",
      "3:\tlearn: 0.9886023\ttotal: 338ms\tremaining: 507ms\n",
      "4:\tlearn: 0.9885601\ttotal: 419ms\tremaining: 419ms\n",
      "5:\tlearn: 0.9886133\ttotal: 498ms\tremaining: 332ms\n",
      "6:\tlearn: 0.9886884\ttotal: 574ms\tremaining: 246ms\n",
      "7:\tlearn: 0.9886569\ttotal: 647ms\tremaining: 162ms\n",
      "8:\tlearn: 0.9889042\ttotal: 724ms\tremaining: 80.4ms\n",
      "9:\tlearn: 0.9890723\ttotal: 797ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9714542257473157 \n",
      "0:\tlearn: 0.9865090\ttotal: 80.5ms\tremaining: 725ms\n",
      "1:\tlearn: 0.9872215\ttotal: 158ms\tremaining: 632ms\n",
      "2:\tlearn: 0.9879853\ttotal: 234ms\tremaining: 546ms\n",
      "3:\tlearn: 0.9885267\ttotal: 310ms\tremaining: 465ms\n",
      "4:\tlearn: 0.9885948\ttotal: 384ms\tremaining: 384ms\n",
      "5:\tlearn: 0.9886159\ttotal: 456ms\tremaining: 304ms\n",
      "6:\tlearn: 0.9886959\ttotal: 527ms\tremaining: 226ms\n",
      "7:\tlearn: 0.9886526\ttotal: 600ms\tremaining: 150ms\n",
      "8:\tlearn: 0.9888654\ttotal: 669ms\tremaining: 74.4ms\n",
      "9:\tlearn: 0.9889813\ttotal: 735ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9712916869408991 \n",
      "0:\tlearn: 0.9865090\ttotal: 85.2ms\tremaining: 767ms\n",
      "1:\tlearn: 0.9872215\ttotal: 165ms\tremaining: 659ms\n",
      "2:\tlearn: 0.9879853\ttotal: 244ms\tremaining: 569ms\n",
      "3:\tlearn: 0.9885252\ttotal: 322ms\tremaining: 483ms\n",
      "4:\tlearn: 0.9885948\ttotal: 398ms\tremaining: 398ms\n",
      "5:\tlearn: 0.9886143\ttotal: 472ms\tremaining: 315ms\n",
      "6:\tlearn: 0.9886897\ttotal: 544ms\tremaining: 233ms\n",
      "7:\tlearn: 0.9887917\ttotal: 617ms\tremaining: 154ms\n",
      "8:\tlearn: 0.9890538\ttotal: 688ms\tremaining: 76.5ms\n",
      "9:\tlearn: 0.9891357\ttotal: 761ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9712510294227745 \n",
      "0:\tlearn: 0.9865090\ttotal: 87.7ms\tremaining: 789ms\n",
      "1:\tlearn: 0.9872167\ttotal: 170ms\tremaining: 680ms\n",
      "2:\tlearn: 0.9879318\ttotal: 252ms\tremaining: 589ms\n",
      "3:\tlearn: 0.9880860\ttotal: 330ms\tremaining: 495ms\n",
      "4:\tlearn: 0.9884635\ttotal: 406ms\tremaining: 406ms\n",
      "5:\tlearn: 0.9885359\ttotal: 479ms\tremaining: 319ms\n",
      "6:\tlearn: 0.9887595\ttotal: 556ms\tremaining: 238ms\n",
      "7:\tlearn: 0.9888958\ttotal: 627ms\tremaining: 157ms\n",
      "8:\tlearn: 0.9888838\ttotal: 697ms\tremaining: 77.4ms\n",
      "9:\tlearn: 0.9890372\ttotal: 764ms\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9710584447190086 \n",
      "0:\tlearn: 0.9879193\ttotal: 142ms\tremaining: 1.28s\n",
      "1:\tlearn: 0.9886318\ttotal: 285ms\tremaining: 1.14s\n",
      "2:\tlearn: 0.9889908\ttotal: 415ms\tremaining: 968ms\n",
      "3:\tlearn: 0.9889815\ttotal: 539ms\tremaining: 808ms\n",
      "4:\tlearn: 0.9890628\ttotal: 659ms\tremaining: 659ms\n",
      "5:\tlearn: 0.9893586\ttotal: 778ms\tremaining: 519ms\n",
      "6:\tlearn: 0.9894433\ttotal: 898ms\tremaining: 385ms\n",
      "7:\tlearn: 0.9896102\ttotal: 1.01s\tremaining: 253ms\n",
      "8:\tlearn: 0.9895614\ttotal: 1.13s\tremaining: 125ms\n",
      "9:\tlearn: 0.9895982\ttotal: 1.24s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9712313866696672 \n",
      "0:\tlearn: 0.9879193\ttotal: 142ms\tremaining: 1.28s\n",
      "1:\tlearn: 0.9886287\ttotal: 286ms\tremaining: 1.14s\n",
      "2:\tlearn: 0.9889627\ttotal: 417ms\tremaining: 972ms\n",
      "3:\tlearn: 0.9890937\ttotal: 543ms\tremaining: 815ms\n",
      "4:\tlearn: 0.9892245\ttotal: 667ms\tremaining: 667ms\n",
      "5:\tlearn: 0.9893378\ttotal: 787ms\tremaining: 525ms\n",
      "6:\tlearn: 0.9894800\ttotal: 906ms\tremaining: 388ms\n",
      "7:\tlearn: 0.9895533\ttotal: 1.02s\tremaining: 255ms\n",
      "8:\tlearn: 0.9896739\ttotal: 1.14s\tremaining: 126ms\n",
      "9:\tlearn: 0.9897073\ttotal: 1.25s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9714349725551698 \n",
      "0:\tlearn: 0.9879193\ttotal: 143ms\tremaining: 1.28s\n",
      "1:\tlearn: 0.9886351\ttotal: 285ms\tremaining: 1.14s\n",
      "2:\tlearn: 0.9888140\ttotal: 413ms\tremaining: 964ms\n",
      "3:\tlearn: 0.9889905\ttotal: 541ms\tremaining: 811ms\n",
      "4:\tlearn: 0.9891365\ttotal: 660ms\tremaining: 660ms\n",
      "5:\tlearn: 0.9893448\ttotal: 779ms\tremaining: 519ms\n",
      "6:\tlearn: 0.9894687\ttotal: 896ms\tremaining: 384ms\n",
      "7:\tlearn: 0.9896106\ttotal: 1.01s\tremaining: 252ms\n",
      "8:\tlearn: 0.9896357\ttotal: 1.12s\tremaining: 125ms\n",
      "9:\tlearn: 0.9896828\ttotal: 1.24s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9715700247543321 \n",
      "0:\tlearn: 0.9879193\ttotal: 143ms\tremaining: 1.29s\n",
      "1:\tlearn: 0.9886350\ttotal: 288ms\tremaining: 1.15s\n",
      "2:\tlearn: 0.9888002\ttotal: 422ms\tremaining: 984ms\n",
      "3:\tlearn: 0.9889616\ttotal: 585ms\tremaining: 878ms\n",
      "4:\tlearn: 0.9891243\ttotal: 703ms\tremaining: 703ms\n",
      "5:\tlearn: 0.9893746\ttotal: 819ms\tremaining: 546ms\n",
      "6:\tlearn: 0.9894940\ttotal: 942ms\tremaining: 404ms\n",
      "7:\tlearn: 0.9896410\ttotal: 1.06s\tremaining: 265ms\n",
      "8:\tlearn: 0.9896700\ttotal: 1.18s\tremaining: 131ms\n",
      "9:\tlearn: 0.9896619\ttotal: 1.29s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9717242931073277 \n",
      "0:\tlearn: 0.9879193\ttotal: 148ms\tremaining: 1.33s\n",
      "1:\tlearn: 0.9886366\ttotal: 292ms\tremaining: 1.17s\n",
      "2:\tlearn: 0.9887955\ttotal: 422ms\tremaining: 985ms\n",
      "3:\tlearn: 0.9889601\ttotal: 551ms\tremaining: 826ms\n",
      "4:\tlearn: 0.9891212\ttotal: 676ms\tremaining: 676ms\n",
      "5:\tlearn: 0.9893700\ttotal: 799ms\tremaining: 532ms\n",
      "6:\tlearn: 0.9894909\ttotal: 919ms\tremaining: 394ms\n",
      "7:\tlearn: 0.9895866\ttotal: 1.04s\tremaining: 260ms\n",
      "8:\tlearn: 0.9896742\ttotal: 1.15s\tremaining: 128ms\n",
      "9:\tlearn: 0.9896951\ttotal: 1.28s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9720678780597688 \n",
      "0:\tlearn: 0.9879193\ttotal: 154ms\tremaining: 1.39s\n",
      "1:\tlearn: 0.9886194\ttotal: 301ms\tremaining: 1.2s\n",
      "2:\tlearn: 0.9890244\ttotal: 434ms\tremaining: 1.01s\n",
      "3:\tlearn: 0.9892554\ttotal: 563ms\tremaining: 844ms\n",
      "4:\tlearn: 0.9892256\ttotal: 688ms\tremaining: 688ms\n",
      "5:\tlearn: 0.9896133\ttotal: 808ms\tremaining: 539ms\n",
      "6:\tlearn: 0.9898565\ttotal: 929ms\tremaining: 398ms\n",
      "7:\tlearn: 0.9899113\ttotal: 1.04s\tremaining: 261ms\n",
      "8:\tlearn: 0.9902471\ttotal: 1.17s\tremaining: 130ms\n",
      "9:\tlearn: 0.9904183\ttotal: 1.29s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9713427230046948 \n",
      "0:\tlearn: 0.9879193\ttotal: 146ms\tremaining: 1.32s\n",
      "1:\tlearn: 0.9886132\ttotal: 291ms\tremaining: 1.16s\n",
      "2:\tlearn: 0.9890514\ttotal: 421ms\tremaining: 982ms\n",
      "3:\tlearn: 0.9892253\ttotal: 545ms\tremaining: 818ms\n",
      "4:\tlearn: 0.9894078\ttotal: 667ms\tremaining: 667ms\n",
      "5:\tlearn: 0.9897385\ttotal: 788ms\tremaining: 526ms\n",
      "6:\tlearn: 0.9899166\ttotal: 907ms\tremaining: 389ms\n",
      "7:\tlearn: 0.9900871\ttotal: 1.05s\tremaining: 262ms\n",
      "8:\tlearn: 0.9902651\ttotal: 1.17s\tremaining: 129ms\n",
      "9:\tlearn: 0.9904043\ttotal: 1.28s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9714477913147469 \n",
      "0:\tlearn: 0.9879193\ttotal: 154ms\tremaining: 1.39s\n",
      "1:\tlearn: 0.9880844\ttotal: 302ms\tremaining: 1.21s\n",
      "2:\tlearn: 0.9889134\ttotal: 438ms\tremaining: 1.02s\n",
      "3:\tlearn: 0.9891034\ttotal: 568ms\tremaining: 852ms\n",
      "4:\tlearn: 0.9892427\ttotal: 700ms\tremaining: 700ms\n",
      "5:\tlearn: 0.9895896\ttotal: 818ms\tremaining: 545ms\n",
      "6:\tlearn: 0.9897682\ttotal: 934ms\tremaining: 400ms\n",
      "7:\tlearn: 0.9900419\ttotal: 1.09s\tremaining: 272ms\n",
      "8:\tlearn: 0.9902814\ttotal: 1.21s\tremaining: 135ms\n",
      "9:\tlearn: 0.9903977\ttotal: 1.33s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9713770565697544 \n",
      "0:\tlearn: 0.9879193\ttotal: 151ms\tremaining: 1.35s\n",
      "1:\tlearn: 0.9880812\ttotal: 295ms\tremaining: 1.18s\n",
      "2:\tlearn: 0.9889118\ttotal: 429ms\tremaining: 1s\n",
      "3:\tlearn: 0.9892054\ttotal: 557ms\tremaining: 836ms\n",
      "4:\tlearn: 0.9893652\ttotal: 686ms\tremaining: 686ms\n",
      "5:\tlearn: 0.9897632\ttotal: 800ms\tremaining: 534ms\n",
      "6:\tlearn: 0.9899989\ttotal: 926ms\tremaining: 397ms\n",
      "7:\tlearn: 0.9901532\ttotal: 1.03s\tremaining: 259ms\n",
      "8:\tlearn: 0.9903507\ttotal: 1.16s\tremaining: 129ms\n",
      "9:\tlearn: 0.9904980\ttotal: 1.27s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.971379271540568 \n",
      "0:\tlearn: 0.9879193\ttotal: 160ms\tremaining: 1.44s\n",
      "1:\tlearn: 0.9886902\ttotal: 308ms\tremaining: 1.23s\n",
      "2:\tlearn: 0.9889256\ttotal: 443ms\tremaining: 1.03s\n",
      "3:\tlearn: 0.9891335\ttotal: 570ms\tremaining: 855ms\n",
      "4:\tlearn: 0.9894504\ttotal: 698ms\tremaining: 698ms\n",
      "5:\tlearn: 0.9896932\ttotal: 818ms\tremaining: 545ms\n",
      "6:\tlearn: 0.9898307\ttotal: 935ms\tremaining: 401ms\n",
      "7:\tlearn: 0.9899400\ttotal: 1.05s\tremaining: 263ms\n",
      "8:\tlearn: 0.9901810\ttotal: 1.17s\tremaining: 130ms\n",
      "9:\tlearn: 0.9903629\ttotal: 1.28s\tremaining: 0us\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9718241347053321 \n",
      "best params:\n",
      "   5    |    9    |  0.03   | 0.43094831490062036 | 0.9727272727272727 \n",
      "predict cat\n"
     ]
    }
   ],
   "source": [
    "number_of_folds = 5\n",
    "for i in range(number_of_folds):\n",
    "    print(f'fold: {i+1}')\n",
    "\n",
    "    train_set_with_features = pd.read_csv(f\"Data/processed_data/train_set_features{i+1}.csv\")\n",
    "    validation_set_with_features = pd.read_csv(f\"Data/processed_data/val_set_features{i+1}.csv\")\n",
    "    test_set_with_features = pd.read_csv(f\"Data/processed_data/test_set_features{i+1}.csv\")\n",
    "\n",
    "    # only keep columns of interest\n",
    "    train_set_with_features = train_set_with_features[columns_to_keep+['label']]\n",
    "    validation_set_with_features = validation_set_with_features[columns_to_keep+['label']]\n",
    "    test_set_with_features = test_set_with_features[columns_to_keep]\n",
    "\n",
    "    train_samples, train_labels = train_set_with_features.drop(columns = ['label']), train_set_with_features[['label']]\n",
    "    validation_samples, validation_labels = validation_set_with_features.drop(columns = ['label']), validation_set_with_features[['label']]\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_samples_scaled = scaler.fit_transform(np.float32(train_samples))\n",
    "    validation_samples_scaled = scaler.transform(np.float32(validation_samples))\n",
    "    test_samples_scaled = scaler.transform(np.float32(test_set_with_features))\n",
    "\n",
    "    if not os.path.isfile(f\"Data/predictions/2preds_mlp_{i+1}.pkl\"):\n",
    "\n",
    "        print(\"train mlp\")\n",
    "        clf_mlp, thresh_mlp = get_best_MLP(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label))\n",
    "        print(\"predict mlp\")\n",
    "        preds_mlp = clf_mlp.predict_proba(test_samples_scaled)[:,1]\n",
    "        pickle.dump((preds_mlp,thresh_mlp), open(f\"Data/predictions/2preds_mlp_{i+1}.pkl\", 'wb'))\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(f\"Data/predictions/2preds_xgb_{i+1}.pkl\"):\n",
    "        print(\"train xgb\")\n",
    "\n",
    "        clf_xgb, thresh_xgb = get_best_xgb(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label))\n",
    "        print(\"predict xgb\")\n",
    "        preds_xgb = clf_xgb.predict_proba(test_samples_scaled)[:,1]\n",
    "        \n",
    "        pickle.dump((preds_xgb,thresh_xgb), open(f\"Data/predictions/2preds_xgb_{i+1}.pkl\", 'wb'))\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isfile(f\"Data/predictions/preds_cat_{i+1}.pkl\"):\n",
    "        print(\"train cat\")\n",
    "\n",
    "        clf_cat, thresh_cat = get_best_catboost(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label))\n",
    "        print(\"predict cat\")\n",
    "        preds_cat = clf_cat.predict_proba(test_samples_scaled)[:,1]\n",
    "        \n",
    "        pickle.dump((preds_cat,thresh_cat), open(f\"Data/predictions/preds_cat_{i+1}.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([])\n",
    "for i in range(number_of_folds):\n",
    "\n",
    "    \n",
    "    preds_xgb,thresh_xgb = pickle.load(open(f\"Data/predictions/preds_xgb_{i+1}.pkl\", 'rb'))\n",
    "    preds_mlp,thresh_mlp = pickle.load(open(f\"Data/predictions/preds_mlp_{i+1}.pkl\", 'rb'))\n",
    "    preds_cat,thresh_cat = pickle.load(open(f\"Data/predictions/preds_cat_{i+1}.pkl\", 'rb'))\n",
    "    \n",
    "    if preds.shape[0]==0:\n",
    "        preds = np.int32(preds_xgb >= thresh_xgb)  + np.int32(preds_mlp >= thresh_mlp) + np.int32(preds_cat >= thresh_cat)\n",
    "\n",
    "    else:\n",
    "        preds += np.int32(preds_xgb >= thresh_xgb)  + np.int32(preds_mlp >= thresh_mlp) + np.int32(preds_cat >= thresh_cat)\n",
    "\n",
    "# majority voting\n",
    "final_preds = np.int32(preds >= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format and save prediction\n",
    "\n",
    "test_set = pd.read_csv(test_set_path, sep =\" \", header = None)\n",
    "test_set.columns = ['node1','node2']\n",
    "\n",
    "## update nodes values to new indices\n",
    "test_set.node1 = test_set.apply(lambda x:id_old2new[x.node1], axis = 1)\n",
    "test_set.node2 = test_set.apply(lambda x:id_old2new[x.node2], axis = 1)\n",
    "\n",
    "\n",
    "test_set['category'] = final_preds\n",
    "\n",
    "test_set = (test_set\n",
    ".reset_index()\n",
    ".rename(columns = {'index':'id'})\n",
    ".drop(columns = ['node1','node2'])\n",
    ")\n",
    "\n",
    "test_set.to_csv('final_predictions_no_emb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6657d8cf73e4192045730bbde1f7a947d4725a27f96025bfcb1ab47bc67665b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
