{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33631\\AppData\\Local\\Temp\\ipykernel_15100\\934934288.py:26: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "import pickle\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score \n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from link_pred.utils import cosine, euclidian, retrieve_and_pre_processed_informations, compute_unique_names\n",
    "from link_pred.folds_creation import create_and_save_folds\n",
    "from link_pred.create_graphs import create_articles_graph, create_co_authorship_graph, create_authors_co_citation_graph\n",
    "from link_pred.node_embeddings import compute_abstracts_embeddings, compute_titles_embeddings, compute_walklets, compute_node2vec, compute_deep_walks\n",
    "from link_pred.edges_features import Jaccard, AdamicAdar, preferential_attachement, are_connected, common_journal\n",
    "from link_pred.models_training import get_best_xgb, get_xgb, get_best_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_path = \"Data/raw_data/node_information.csv\"\n",
    "test_set_path = \"Data/raw_data/testing_set.txt\"\n",
    "train_set_path = \"Data/raw_data/training_set.txt\"\n",
    "random_preds_path = \"Data/raw_data/random_predictions.csv\"\n",
    "\n",
    "number_of_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and pre_process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_df = retrieve_and_pre_processed_informations(information_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new id to each node (needs to start from 0)\n",
    "id_old2new = {k: v for v, k in enumerate(list(information_df.ID))}\n",
    "id_new2old = {v: k for v, k in id_old2new.items()}\n",
    "\n",
    "information_df['new_ID'] = information_df.ID.apply(lambda x: id_old2new[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_set = pd.read_csv(train_set_path, sep =\" \", header = None)\n",
    "initial_train_set.columns = ['node1','node2','label']\n",
    "\n",
    "## update nodes values to new indices\n",
    "initial_train_set.node1 = initial_train_set.apply(lambda x:id_old2new[x.node1], axis = 1)\n",
    "initial_train_set.node2 = initial_train_set.apply(lambda x:id_old2new[x.node2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test set\n",
    "\n",
    "test_set = pd.read_csv(test_set_path, sep =\" \", header = None)\n",
    "test_set.columns = ['node1','node2']\n",
    "\n",
    "## update nodes values to new indices\n",
    "test_set.node1 = test_set.apply(lambda x:id_old2new[x.node1], axis = 1)\n",
    "test_set.node2 = test_set.apply(lambda x:id_old2new[x.node2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 already exists !\n",
      "fold 2 already exists !\n",
      "fold 3 already exists !\n",
      "fold 4 already exists !\n",
      "fold 5 already exists !\n"
     ]
    }
   ],
   "source": [
    "create_and_save_folds(initial_train_set, number_of_folds = number_of_folds, validation_size = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with authors various names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# convert to lower case, remove punctuation, strip the names\n",
    "authors_raw_set = set([auth.strip().lower().translate(str.maketrans('', '', string.punctuation)) for list_auth in information_df.authors for auth in list_auth if len(auth)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several authors can be named differently (eg. Jean DUPONT, J.Dupont, etc.)\n",
    "# we create a name matcher function to try to indentify each author and assign each denomination a \"representant\"\n",
    "\n",
    "if os.path.isfile('Data/processed_data/representant_dict.pkl'):\n",
    "    representant_dict = pickle.load(open('Data/processed_data/representant_dict.pkl','rb'))\n",
    "else:\n",
    "    representant_dict = compute_unique_names(authors_raw_set)\n",
    "    pickle.dump(representant_dict, open('Data/processed_data/representant_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each name to its representant value\n",
    "information_df.authors = information_df.authors.apply(lambda x: [representant_dict[auth.strip().lower().translate(str.maketrans('', '', string.punctuation))] for auth in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_lemma</th>\n",
       "      <th>new_ID</th>\n",
       "      <th>authors_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1213</td>\n",
       "      <td>2000</td>\n",
       "      <td>noncommutative and ordinary super yang-mills o...</td>\n",
       "      <td>[ronggen cai, nobuyoshi ohta]</td>\n",
       "      <td>JHEP</td>\n",
       "      <td>states we study properties of d p-2 d p nonthr...</td>\n",
       "      <td>[noncommutative, ordinary, super, yang, mill, ...</td>\n",
       "      <td>203</td>\n",
       "      <td>[5854, 9008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25627</th>\n",
       "      <td>9903221</td>\n",
       "      <td>1999</td>\n",
       "      <td>product integral representations of wilson lin...</td>\n",
       "      <td>[rl karp, f mansouri, js rno]</td>\n",
       "      <td>Turk.J.Phys.</td>\n",
       "      <td>non-abelian stokes theorem we make use of prod...</td>\n",
       "      <td>[product, integral, representation, wilson, li...</td>\n",
       "      <td>25627</td>\n",
       "      <td>[8833, 7954, 14049]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  pub_year                                              title  \\\n",
       "203       1213      2000  noncommutative and ordinary super yang-mills o...   \n",
       "25627  9903221      1999  product integral representations of wilson lin...   \n",
       "\n",
       "                             authors  journal_name  \\\n",
       "203    [ronggen cai, nobuyoshi ohta]          JHEP   \n",
       "25627  [rl karp, f mansouri, js rno]  Turk.J.Phys.   \n",
       "\n",
       "                                                abstract  \\\n",
       "203    states we study properties of d p-2 d p nonthr...   \n",
       "25627  non-abelian stokes theorem we make use of prod...   \n",
       "\n",
       "                                             title_lemma  new_ID  \\\n",
       "203    [noncommutative, ordinary, super, yang, mill, ...     203   \n",
       "25627  [product, integral, representation, wilson, li...   25627   \n",
       "\n",
       "                authors_id  \n",
       "203           [5854, 9008]  \n",
       "25627  [8833, 7954, 14049]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique index for each author\n",
    "representants_list = list(set(representant_dict.values()))\n",
    "authors2idx = {k: v for v, k in enumerate(representants_list)}\n",
    "information_df[\"authors_id\"] = information_df.authors.apply(lambda x: [authors2idx[auth] for auth in x])\n",
    "\n",
    "information_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_authors_co_auth = create_co_authorship_graph(information_df, authors2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# those embeddings do not depend on the fold\n",
    "abstracts_embeddings = compute_abstracts_embeddings(information_df)\n",
    "abstracts_embeddings = compute_titles_embeddings(information_df)\n",
    "\n",
    "\n",
    "if os.path.isfile(f'Data/embeddings/walklets_co_auth_embeddings.pkl'):\n",
    "    walklets_co_auth_embeddings = pickle.load(open('Data/embeddings/walklets_co_auth_embeddings.pkl','rb'))\n",
    "else:\n",
    "    walklets_co_auth_embeddings = compute_walklets(G_authors_co_auth)\n",
    "    pickle.dump(walklets_co_auth_embeddings,open('Data/embeddings/walklets_co_auth_embeddings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n"
     ]
    }
   ],
   "source": [
    "# those embeddings depend on the fold\n",
    "for i in range(number_of_folds):\n",
    "    print(f\"fold: {i+1}\")\n",
    "\n",
    "    train_set = pd.read_csv(f\"Data/folds/train_set_{i+1}\")\n",
    "    articles_graph = create_articles_graph(train_set,information_df)\n",
    "    authors_citation_graph = create_authors_co_citation_graph(train_set, information_df, authors2idx)\n",
    "\n",
    "    if os.path.isfile(f'Data/embeddings/articles_walklets_{i+1}.pkl') == False:\n",
    "        walklets_articles_embeddings = compute_walklets(articles_graph)\n",
    "        pickle.dump(walklets_articles_embeddings, open(f'Data/embeddings/articles_walklets_{i+1}.pkl','wb'))\n",
    "    if os.path.isfile(f'Data/embeddings/articles_node2vec_{i+1}.pkl') == False:\n",
    "        node2vec_articles_embeddings = compute_node2vec(articles_graph)\n",
    "        pickle.dump(node2vec_articles_embeddings, open(f'Data/embeddings/articles_node2vec_{i+1}.pkl','wb'))\n",
    "    if os.path.isfile(f'Data/embeddings/co_citation_walklets_{i+1}.pkl') == False:\n",
    "        walklets_co_citation_embeddings = compute_walklets(authors_citation_graph)\n",
    "        pickle.dump(walklets_co_citation_embeddings, open(f'Data/embeddings/co_citation_walklets_{i+1}.pkl','wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_non_embeddings_features(df, information_df, G_articles):\n",
    "    information_df['new_ID'] = information_df.ID.apply(lambda x:id_old2new[x])\n",
    "    useful_information_df = information_df[['new_ID','authors','pub_year', 'title_lemma']]\n",
    "\n",
    "    # prepare data frame for common authors computation\n",
    "    df = (df\n",
    "    .merge(useful_information_df, how ='left', left_on = ['node1'], right_on = ['new_ID'])\n",
    "    .rename(columns = {'authors':'authors_node_1', 'pub_year':'pub_year1', 'title_lemma':'title_lemma1'})\n",
    "    .merge(useful_information_df, how ='left', left_on = ['node2'], right_on = ['new_ID'])\n",
    "    .rename(columns = {'authors':'authors_node_2', 'pub_year':'pub_year2', 'title_lemma':'title_lemma2'})\n",
    "    )\n",
    "\n",
    "    ### Compute page rank\n",
    "    page_rank_dict = nx.pagerank(G_articles)\n",
    "\n",
    "    ### compute degree centrality\n",
    "    centrality_dict = nx.degree_centrality(G_articles)\n",
    "\n",
    "    ### convert to undirect for jacard\n",
    "    G_articles_undirected = G_articles.to_undirected()\n",
    "\n",
    "    print('computing resource_allocation')\n",
    "    df['resource_allocation'] = df.apply(lambda x:list(nx.resource_allocation_index(G_articles_undirected ,[(x.node1, x.node2)]))[0],axis = 1)\n",
    "\n",
    "    print(\"common_journal\")\n",
    "    df['common_journals'] = df.apply(lambda x: common_journal(information_df, x.node1, x.node2),axis = 1)\n",
    "    \n",
    "    print('computing common authors')\n",
    "    #  compute common authors\n",
    "    df['common_authors'] = df.apply(lambda x:len(set(x.authors_node_1)&set(x.authors_node_2)),axis = 1)\n",
    "\n",
    "    print('computing common words')\n",
    "    #  compute common words in titles\n",
    "    df['common_title_words'] = df.apply(lambda x:len(set(x.title_lemma1)&set(x.title_lemma2)),axis = 1)\n",
    "\n",
    "    print('computing delta publication year')\n",
    "    # compute delta publication year\n",
    "    df['delta_publication'] = df.apply(lambda x:np.abs(x.pub_year2 - x.pub_year1),axis = 1)\n",
    "\n",
    "    # compute edges features\n",
    "    print('computing jacard index')\n",
    "    df['jacard'] = df.apply(lambda x: Jaccard(G_articles_undirected, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('computing preferential attachement')\n",
    "    df['pa'] = df.apply(lambda x: preferential_attachement(G_articles_undirected, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('computing adamic_adar')\n",
    "    df['adamic_adar'] = df.apply(lambda x: AdamicAdar(G_articles_undirected, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('are connected')\n",
    "    df['connection'] = df.apply(lambda x: are_connected(G_articles, (x.node1, x.node2)),axis = 1)\n",
    "\n",
    "    print('page ranks')\n",
    "    df['page_rank1'] = df.apply(lambda x: page_rank_dict[x.node1],axis = 1)\n",
    "    df['page_rank2'] = df.apply(lambda x: page_rank_dict[x.node2],axis = 1)\n",
    "    \n",
    "    print('compute degree')\n",
    "\n",
    "    df['degree1'] = df.apply(lambda x: centrality_dict[x.node1],axis = 1)\n",
    "    df['degree2'] = df.apply(lambda x: centrality_dict[x.node2],axis = 1)\n",
    "\n",
    "    \n",
    "    df = df.fillna({ 'jacard':df.jacard.mean(),\n",
    "                     'adamic_adar':df.adamic_adar.mean()\n",
    "                     })\n",
    "\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_features(df,\n",
    "                                information_df,\n",
    "                                abstracts_embeddings,\n",
    "                                walklets_articles_embeddings,\n",
    "                                walklets_co_auth_embeddings,\n",
    "                                walklets_co_citation_embeddings,\n",
    "                                node2vec_articles_embeddings,\n",
    "                                pca = True):\n",
    "\n",
    "    # for each article take a mean of the authors embedding as global autors embedding (idem for citation)\n",
    "    articles_authors_embedding = []\n",
    "    articles_authors_embedding_citation = []\n",
    "    for i in range(information_df.shape[0]):\n",
    "        value = information_df[information_df.new_ID == i]\n",
    "        authors_id = value.authors_id\n",
    "        embeddings = np.array([0 for i in range(128)]).astype('float64')\n",
    "        embeddings_citation = np.array([0 for i in range(128)]).astype('float64')\n",
    "        for author in authors_id:\n",
    "            embeddings+=walklets_co_auth_embeddings[author][0]\n",
    "            embeddings_citation+=walklets_co_citation_embeddings[author][0]\n",
    "        articles_authors_embedding.append(embeddings/len(authors_id))\n",
    "        articles_authors_embedding_citation.append(embeddings_citation/len(authors_id))\n",
    "\n",
    "\n",
    "    # compute some cosine and euclidian based distances\n",
    "    df['articles_walklets_cosine'] = df.apply(lambda x:cosine(walklets_articles_embeddings[x.node1],walklets_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['articles_node2vec_cosine'] = df.apply(lambda x:cosine(node2vec_articles_embeddings[x.node1],node2vec_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['abstracts_embeddings_cosine'] = df.apply(lambda x:cosine(abstracts_embeddings[x.node1][0],abstracts_embeddings[x.node2][0]), axis = 1)\n",
    "    \n",
    "    df['articles_walklets_euclidian'] = df.apply(lambda x:euclidian(walklets_articles_embeddings[x.node1],walklets_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['articles_node2vec_euclidian'] = df.apply(lambda x:euclidian(node2vec_articles_embeddings[x.node1],node2vec_articles_embeddings[x.node2]), axis = 1)\n",
    "    df['abstracts_embeddings_euclidian'] = df.apply(lambda x:euclidian(abstracts_embeddings[x.node1][0],abstracts_embeddings[x.node2][0]), axis = 1)\n",
    "    \n",
    "    # compute some cosine and euclidian based distances for authors\n",
    "    df['co_authorship_embeddings_cosine'] = df.apply(lambda x:cosine(articles_authors_embedding[x.node1],articles_authors_embedding[x.node2]), axis = 1)\n",
    "    df['authors_embeddings_cosine_citation'] = df.apply(lambda x:cosine(articles_authors_embedding_citation[x.node1],articles_authors_embedding_citation[x.node2]), axis = 1)    \n",
    "    df['co_authorship_embeddings_euclidian'] = df.apply(lambda x:euclidian(articles_authors_embedding[x.node1],articles_authors_embedding[x.node2]), axis = 1)\n",
    "    df['authors_embeddings_euclidian_citation'] = df.apply(lambda x:euclidian(articles_authors_embedding_citation[x.node1],articles_authors_embedding_citation[x.node2]), axis = 1)\n",
    "    \n",
    "    # node1 and node2 article embedding\n",
    "    print(\"add articles walklets embeddings\")\n",
    "    # only append vectors of size 10 that represent articles embeddings (quicker to compute)\n",
    "    if pca:\n",
    "        pca_walklets= PCA(n_components = 5)\n",
    "        walklets_articles_embeddings = pca_walklets.fit_transform(walklets_articles_embeddings)\n",
    "        pca_node2vec =  PCA(n_components = 5)\n",
    "        node2vec_articles_embeddings = pca_node2vec.fit_transform(node2vec_articles_embeddings)\n",
    "\n",
    "\n",
    "    walklets_node_embeddings_df = pd.DataFrame(walklets_articles_embeddings, columns = [f'emb_walklets_{i}' for i in range(len(walklets_articles_embeddings[0]))])\n",
    "    walklets_node_embeddings_df = walklets_node_embeddings_df.reset_index().rename(columns = {'index':'node'})\n",
    "    df = (df\n",
    "        .merge(walklets_node_embeddings_df, how ='left', left_on = ['node1'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "        .merge(walklets_node_embeddings_df, how ='left', left_on = ['node2'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "    )\n",
    "\n",
    "    print(\"add articles node2vecs embeddings\")\n",
    "    # only append vectors of size 10 that represent articles embeddings (quicker to compute)\n",
    "\n",
    "    node_node2vec_embeddings_df = pd.DataFrame(node2vec_articles_embeddings, columns = [f'emb_node2vec{i}' for i in range(len(node2vec_articles_embeddings[0]))])\n",
    "    node_node2vec_embeddings_df = node_node2vec_embeddings_df.reset_index().rename(columns = {'index':'node'})\n",
    "    df = (df\n",
    "        .merge(node_node2vec_embeddings_df, how ='left', left_on = ['node1'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "        .merge(node_node2vec_embeddings_df, how ='left', left_on = ['node2'], right_on = ['node'])\n",
    "        .drop(columns = ['node'])\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compute features for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_folds):\n",
    "    print(f\"fold: {i+1}\")\n",
    "    if os.path.isfile(f\"Data/processed_data/train_set_features{i+1}.csv\") and os.path.isfile(f\"Data/processed_data/val_set_features{i+1}.csv\") and os.path.isfile(f\"Data/processed_data/test_set_features{i+1}.csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        # load sets\n",
    "        train_set = pd.read_csv(f\"Data/folds/train_set_{i+1}\")\n",
    "        validation_set = pd.read_csv(f\"Data/folds/validation_set_{i+1}\")\n",
    "\n",
    "        # compute graphs\n",
    "        G_articles = create_articles_graph(train_set,information_df)\n",
    "\n",
    "        # load embeddings\n",
    "        walklets_articles_embeddings = pickle.load(open(f'Data/embeddings/articles_walklets_{i+1}.pkl','rb'))\n",
    "        walklets_co_citation_embeddings = pickle.load(open(f'Data/embeddings/co_citation_walklets_{i+1}.pkl','rb'))\n",
    "        node2vec_articles_embeddings = pickle.load(open(f'Data/embeddings/articles_node2vec_{i+1}.pkl','rb'))\n",
    "\n",
    "        # compute features for train\n",
    "        print(\"compute train features\")\n",
    "        train_set_with_features = compute_non_embeddings_features(train_set, information_df, G_articles)\n",
    "        train_set_with_features = compute_embedding_features(train_set_with_features, information_df, abstracts_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True)\n",
    "        # compute features for val\n",
    "        print(\"compute validation features\")\n",
    "        val_set_with_features = compute_non_embeddings_features(validation_set, information_df, G_articles)\n",
    "        val_set_with_features = compute_embedding_features(val_set_with_features, information_df, abstracts_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True)\n",
    "\n",
    "        # compute features for test\n",
    "        print(\"compute test features\")\n",
    "        test_set_with_features = compute_non_embeddings_features(test_set, information_df, G_articles)\n",
    "        test_set_with_features = compute_embedding_features(test_set_with_features, information_df, abstracts_embeddings,\n",
    "                                                                walklets_articles_embeddings,\n",
    "                                                                walklets_co_auth_embeddings,\n",
    "                                                                walklets_co_citation_embeddings,\n",
    "                                                                node2vec_articles_embeddings,\n",
    "                                                                pca = True))\n",
    "\n",
    "        train_set_with_features.to_csv(f\"Data/processed_data/train_set_features{i+1}.csv\", index = False)\n",
    "        val_set_with_features.to_csv(f\"Data/processed_data/val_set_features{i+1}.csv\", index = False)\n",
    "        test_set_with_features.to_csv(f\"Data/processed_data/test_set_features{i+1}.csv\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute columns of interest\n",
    "all_columns = set(pd.read_csv(\"Data/processed_data/train_set_features1.csv\").columns)\n",
    "\n",
    "to_remove = set(['node1', 'node2', 'label', 'new_ID_x', 'authors_node_1',\n",
    "       'title_lemma1', 'new_ID_y', 'authors_node_2', 'title_lemma2','resource_allocation'])\n",
    "columns_to_keep= list(all_columns-to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size = 2):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(input_size, int(input_size/2)),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(int(input_size/2)),\n",
    "                    nn.Linear(int(input_size/2), int(input_size/4)),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(int(input_size/4)),\n",
    "                    nn.Linear(int(input_size/4), output_size)\n",
    "                    )\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "class Dataset(Dataset):\n",
    "  def __init__(self,set_df, labels):\n",
    "    self.x=torch.tensor(set_df,dtype=torch.float32)\n",
    "    self.y=torch.tensor(labels,dtype=torch.long)\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "\n",
    "\n",
    "def train_one_epoch(model, trainloader, validationloader, optimizer, device): \n",
    "    losses = []\n",
    "    val_auroc = torchmetrics.AUROC(num_classes = 2)\n",
    "    val_f1 = torchmetrics.F1Score(num_classes = 2)\n",
    "    train_f1 = torchmetrics.F1Score(num_classes = 2)\n",
    "    model.train()\n",
    "    for (features, target) in tqdm(trainloader):\n",
    "        features, target = features.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(features)\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "      \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(predictions, target)\n",
    "        losses.append(float(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        f1_train = train_f1(predicted_classes.cpu(), target.cpu())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for (features, target) in (validationloader):\n",
    "          features, target = features.to(device), target.to(device)\n",
    "\n",
    "          predictions = model(features)\n",
    "          predicted_classes = torch.argmax(predictions, dim=1)\n",
    "          \n",
    "          validation_auroc = val_auroc(predictions.cpu(), target.cpu())\n",
    "          f1_val = val_f1(predicted_classes.cpu(), target.cpu())\n",
    "\n",
    "    print(\"NN\")\n",
    "          \n",
    "    print('average train loss: ', np.mean(losses))\n",
    "\n",
    "    print('validation f1: ', val_f1.compute())\n",
    "    print('train f1: ', train_f1.compute())\n",
    "    print('validation auroc: ', val_auroc.compute())\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_neural_net(train_samples_scaled, train_labels, validation_samples_scaled, validation_labels, device = 'cuda'):\n",
    "    training_set = Dataset(train_samples_scaled, train_labels)\n",
    "    validation_set = Dataset(validation_samples_scaled, validation_labels)\n",
    "    train_loader = DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_set, batch_size=64, shuffle=True)\n",
    "    clf = Net(input_size = train_samples_scaled.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(clf.parameters(), lr = 0.1)\n",
    "    for epoch in range(0, 5):\n",
    "        train_one_epoch(clf , train_loader, validation_loader, optimizer,device)\n",
    "    return(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      " 23%|██▎       | 2145/9149 [00:49<02:40, 43.63it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\run_models.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000045?line=0'>1</a>\u001b[0m get_neural_net(train_samples_scaled, \u001b[39mlist\u001b[39;49m(train_labels\u001b[39m.\u001b[39;49mlabel), validation_samples_scaled, \u001b[39mlist\u001b[39;49m(validation_labels\u001b[39m.\u001b[39;49mlabel), device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\run_models.ipynb Cell 28'\u001b[0m in \u001b[0;36mget_neural_net\u001b[1;34m(train_samples_scaled, train_labels, validation_samples_scaled, validation_labels, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=80'>81</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(clf\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=81'>82</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=82'>83</a>\u001b[0m     train_one_epoch(clf , train_loader, validation_loader, optimizer,device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=83'>84</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(clf)\n",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\run_models.ipynb Cell 28'\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, trainloader, validationloader, optimizer, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=48'>49</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=49'>50</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=50'>51</a>\u001b[0m     f1_train \u001b[39m=\u001b[39m train_f1(predicted_classes\u001b[39m.\u001b[39;49mcpu(), target\u001b[39m.\u001b[39;49mcpu())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=52'>53</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/run_models.ipynb#ch0000046?line=53'>54</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\metric.py:205\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=198'>199</a>\u001b[0m     \u001b[39mraise\u001b[39;00m TorchMetricsUserError(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=199'>200</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe Metric shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be synced when performing ``update``. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=200'>201</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mHINT: Did you forget to call ``unsync`` ?.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=201'>202</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=203'>204</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=206'>207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_on_step:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=207'>208</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_sync \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_on_step\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\metric.py:263\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=260'>261</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=261'>262</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_called \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/metric.py?line=262'>263</a>\u001b[0m \u001b[39mreturn\u001b[39;00m update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:203\u001b[0m, in \u001b[0;36mStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=192'>193</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, preds: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=193'>194</a>\u001b[0m     \u001b[39m\"\"\"Update state with predictions and targets. See\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=194'>195</a>\u001b[0m \u001b[39m    :ref:`references/modules:input types` for more information on input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=195'>196</a>\u001b[0m \u001b[39m    types.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=199'>200</a>\u001b[0m \u001b[39m        target: Ground truth values\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=200'>201</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=202'>203</a>\u001b[0m     tp, fp, tn, fn \u001b[39m=\u001b[39m _stat_scores_update(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=203'>204</a>\u001b[0m         preds,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=204'>205</a>\u001b[0m         target,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=205'>206</a>\u001b[0m         reduce\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=206'>207</a>\u001b[0m         mdmc_reduce\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmdmc_reduce,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=207'>208</a>\u001b[0m         threshold\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=208'>209</a>\u001b[0m         num_classes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=209'>210</a>\u001b[0m         top_k\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=210'>211</a>\u001b[0m         multiclass\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticlass,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=211'>212</a>\u001b[0m         ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=212'>213</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=214'>215</a>\u001b[0m     \u001b[39m# Update states\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/classification/stat_scores.py?line=215'>216</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduce \u001b[39m!=\u001b[39m AverageMethod\u001b[39m.\u001b[39mSAMPLES \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmdmc_reduce \u001b[39m!=\u001b[39m MDMCAverageMethod\u001b[39m.\u001b[39mSAMPLEWISE:\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:112\u001b[0m, in \u001b[0;36m_stat_scores_update\u001b[1;34m(preds, target, reduce, mdmc_reduce, num_classes, top_k, threshold, multiclass, ignore_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=75'>76</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_stat_scores_update\u001b[39m(\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=76'>77</a>\u001b[0m     preds: Tensor,\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=77'>78</a>\u001b[0m     target: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=84'>85</a>\u001b[0m     ignore_index: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=85'>86</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor, Tensor, Tensor]:\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=86'>87</a>\u001b[0m     \u001b[39m\"\"\"Updates and returns the the number of true positives, false positives, true negatives, false negatives.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=87'>88</a>\u001b[0m \u001b[39m    Raises ValueError if:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=88'>89</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=108'>109</a>\u001b[0m \u001b[39m            as ``-1``.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=109'>110</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=111'>112</a>\u001b[0m     preds, target, _ \u001b[39m=\u001b[39m _input_format_classification(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=112'>113</a>\u001b[0m         preds, target, threshold\u001b[39m=\u001b[39;49mthreshold, num_classes\u001b[39m=\u001b[39;49mnum_classes, multiclass\u001b[39m=\u001b[39;49mmulticlass, top_k\u001b[39m=\u001b[39;49mtop_k\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=113'>114</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=115'>116</a>\u001b[0m     \u001b[39mif\u001b[39;00m ignore_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ignore_index \u001b[39m<\u001b[39m preds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/functional/classification/stat_scores.py?line=116'>117</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe `ignore_index` \u001b[39m\u001b[39m{\u001b[39;00mignore_index\u001b[39m}\u001b[39;00m\u001b[39m is not valid for inputs with \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m classes\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:392\u001b[0m, in \u001b[0;36m_input_format_classification\u001b[1;34m(preds, target, threshold, top_k, num_classes, multiclass)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=388'>389</a>\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=389'>390</a>\u001b[0m     preds \u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=391'>392</a>\u001b[0m case \u001b[39m=\u001b[39m _check_classification_inputs(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=392'>393</a>\u001b[0m     preds,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=393'>394</a>\u001b[0m     target,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=394'>395</a>\u001b[0m     threshold\u001b[39m=\u001b[39;49mthreshold,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=395'>396</a>\u001b[0m     num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=396'>397</a>\u001b[0m     multiclass\u001b[39m=\u001b[39;49mmulticlass,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=397'>398</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49mtop_k,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=398'>399</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=400'>401</a>\u001b[0m \u001b[39mif\u001b[39;00m case \u001b[39min\u001b[39;00m (DataType\u001b[39m.\u001b[39mBINARY, DataType\u001b[39m.\u001b[39mMULTILABEL) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m top_k:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=401'>402</a>\u001b[0m     preds \u001b[39m=\u001b[39m (preds \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold)\u001b[39m.\u001b[39mint()\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:273\u001b[0m, in \u001b[0;36m_check_classification_inputs\u001b[1;34m(preds, target, threshold, num_classes, multiclass, top_k)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=270'>271</a>\u001b[0m     _check_num_classes_binary(num_classes, multiclass)\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=271'>272</a>\u001b[0m \u001b[39melif\u001b[39;00m case \u001b[39min\u001b[39;00m (DataType\u001b[39m.\u001b[39mMULTICLASS, DataType\u001b[39m.\u001b[39mMULTIDIM_MULTICLASS):\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=272'>273</a>\u001b[0m     _check_num_classes_mc(preds, target, num_classes, multiclass, implied_classes)\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=273'>274</a>\u001b[0m \u001b[39melif\u001b[39;00m case\u001b[39m.\u001b[39mMULTILABEL:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=274'>275</a>\u001b[0m     _check_num_classes_ml(num_classes, multiclass, implied_classes)\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\MLNS\\MLNS_Kaggle_Challenge\\venv\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:152\u001b[0m, in \u001b[0;36m_check_num_classes_mc\u001b[1;34m(preds, target, num_classes, multiclass, implied_classes)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m multiclass \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m implied_classes \u001b[39m!=\u001b[39m num_classes:\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=144'>145</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=145'>146</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou have set `multiclass=False`, but the implied number of classes \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=146'>147</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (from shape of inputs) does not match `num_classes`. If you are trying to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=149'>150</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m See Input Types in Metrics documentation.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=150'>151</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=151'>152</a>\u001b[0m \u001b[39mif\u001b[39;00m num_classes \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m target\u001b[39m.\u001b[39;49mmax():\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=152'>153</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe highest label in `target` should be smaller than `num_classes`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/MLNS/MLNS_Kaggle_Challenge/venv/lib/site-packages/torchmetrics/utilities/checks.py?line=153'>154</a>\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m num_classes \u001b[39m!=\u001b[39m implied_classes:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_neural_net(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label), device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_folds):\n",
    "    print(f'fold: {i+1}')\n",
    "    if os.path.isfile(f\"Data/models/scaler_{i+1}.pkl\"):\n",
    "        continue\n",
    "    else:\n",
    "        train_set_with_features = pd.read_csv(f\"Data/processed_data/train_set_features{i+1}.csv\")\n",
    "        validation_set_with_features = pd.read_csv(f\"Data/processed_data/val_set_features{i+1}.csv\")\n",
    "\n",
    "        # only keep columns of interest\n",
    "        train_set_with_features = train_set_with_features[columns_to_keep+['label']]\n",
    "        validation_set_with_features = validation_set_with_features[columns_to_keep+['label']]\n",
    "\n",
    "        train_samples, train_labels = train_set_with_features.drop(columns = ['label']), train_set_with_features[['label']]\n",
    "        validation_samples, validation_labels = validation_set_with_features.drop(columns = ['label']), validation_set_with_features[['label']]\n",
    "        \n",
    "\n",
    "        # scale data\n",
    "        scaler = StandardScaler()\n",
    "        train_samples_scaled = scaler.fit_transform(np.float32(train_samples))\n",
    "        validation_samples_scaled = scaler.transform(np.float32(validation_samples))\n",
    "\n",
    "\n",
    "        # train classifier (grid search best params)\n",
    "        clf_xgb, thresh_xgb = get_best_xgb(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label))\n",
    "        clf_mlp, thresh_mlp = get_best_MLP(train_samples_scaled, list(train_labels.label), validation_samples_scaled, list(validation_labels.label))\n",
    "     \n",
    "    \n",
    "        pickle.dump((clf_xgb,thresh_xgb), open(f\"Data/models/clf_xgb_{i+1}.pkl\", 'wb'))\n",
    "        pickle.dump((clf_mlp,thresh_mlp), open(f\"Data/models/clf_mlp_{i+1}.pkl\", 'wb'))\n",
    "        pickle.dump(scaler, open(f\"Data/models/scaler_{i+1}.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([])\n",
    "for i in range(number_of_folds):\n",
    "    \n",
    "    test_set_with_features = pd.read_csv(f\"Data/processed_data/test_set_features{i+1}.csv\")\n",
    "\n",
    "    # scale data\n",
    "    scaler = pickle.load(open(f\"Data/models/scaler_{i+1}.pkl\", 'rb'))\n",
    "\n",
    "    # only keep columns of interest\n",
    "    test_set_with_features = test_set_with_features[columns_to_keep]\n",
    "\n",
    "    test_set_with_features = scaler.transform(np.float32(test_set_with_features))\n",
    "\n",
    "\n",
    "    # train classifier (grid search best params)\n",
    "    clf, thresh = pickle.load(open(f\"Data/models/clf_{i+1}.pkl\", 'rb'))\n",
    "\n",
    "\n",
    "    if preds.shape[0]==0:\n",
    "        preds = np.array(np.int32(clf.predict_proba(test_set_with_features)[:,1] >= thresh))\n",
    "    else:\n",
    "        preds += np.array(np.int32(clf.predict_proba(test_set_with_features)[:,1] >= thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting \n",
    "test_set['category'] = preds\n",
    "\n",
    "test_set = (test_set\n",
    ".reset_index()\n",
    ".rename(columns = {'index':'id'})\n",
    ".drop(columns = ['node1','node2'])\n",
    ")\n",
    "\n",
    "test_set.to_csv('final_predictions_no_emb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6657d8cf73e4192045730bbde1f7a947d4725a27f96025bfcb1ab47bc67665b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
